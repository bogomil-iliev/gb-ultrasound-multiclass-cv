# -*- coding: utf-8 -*-
"""SummerProject_2011184.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gDyn_WXGn3repUKswgfRuNbnHzNo2Alf

Course: MSc. Artificial Intelligence 2024 - 2025 (September Start)
Module Name and Code: Project Summer Module (COM7303-24-UOB-Q)
Student Name: Bogomil Iliev
Student ID: 2011184
Supervisor: PhD. Naveed Islam

Project Name: Detection and Classification of Gallbladder Diseases through Lightweight Deep Learning Techniques.

# 1. Environment Setup

1.1. Checking what CPU/GPU you are connected to. Accessing GoogleDrive
"""

#Checking the GPU the notebook is connected to.
gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

#Load the Drive helper and mount the Gdrive.
from google.colab import drive
drive.mount('/content/drive')

#Check current Python Version - Should be Python v.3.11.13
import sys
print(sys.version)

"""1.2. Dataset download. Change the Download directory to your own, if you are running the Code!!!"""

#Importing Path from pathlib library - to work easier with file paths.
from pathlib import Path

# Setting Paths
ZIP_URL   = "https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/r6h24d2d3y-1.zip" #Do NOT change this path. It is the direct link to download the dataset.
DEST_DIR  = Path("/content/drive/MyDrive/AI/Project_Summer_Module")   #CHANGE your chosen DESTINATION folder where you want to save the dataset.
LOCAL_ZIP = Path("/content") / "UIdataGB_dataset.zip"                  #Temporary download path for the zip.

#Create destination (if it doesn’t exist)
DEST_DIR.mkdir(parents=True, exist_ok=True)

print(f"Zip will be downloaded to: {LOCAL_ZIP}")
print(f"Dataset will be extracted to: {DEST_DIR}")

#Setting up the downloading of the Dataset from the URL safely and resumably, showing a progress bar.

#Importing of Libraries needed.
import requests #requests is a HTTP client library. Used for HEAD/GET requests, streaming content, handling timeouts, and headers.
from tqdm.auto import tqdm #automatically picks a progress-bar backend that works in notebooks or terminals, and updates it as bytes arrive.


"""
    The get_remote_size(url) method tries to obtain the remote file size in bytes.
    - Makes a HEAD request to read the 'Content-Length' header.
    - If the server doesn't return it on HEAD, falls back to a streaming GET.
    Returns: int size in bytes, or None if unknown.
"""
def get_remote_size(url):
    #Try to obtain remote file size (bytes).
    try:
      #Quick metadata check
        r = requests.head(url, allow_redirects=True, timeout=20)
        size = r.headers.get("Content-Length")
        if not size:
          #Some servers don't give size on HEAD; try GET headers instead.
            r = requests.get(url, stream=True, timeout=20)
            size = r.headers.get("Content-Length")
        return int(size) if size else None
    except Exception:
      #If anything goes wrong (e.g., network), treat size as unknown.
        return None





"""
    Stream-download a file with resume support and a progress bar.

    Args:
      url (str): remote file URL
      dst (pathlib.Path): local destination path (final filename)
      chunk_size (int): read size per network iteration (default 1 MiB)

    Behavior:
      - Writes to 'dst.suffix + .part' first (temp file).
      - If that temp file exists, resumes from its current size using HTTP Range.
      - Shows a tqdm progress bar (bytes), with a total if known.
      - On success, renames the temp file to 'dst' atomically.
"""

def download_with_resume(url, dst, chunk_size=2**20):

    #Ensure destination directory exists.
    dst.parent.mkdir(parents=True, exist_ok=True)

    #Temp file we write to while downloading.
    temp_path = dst.with_suffix(dst.suffix + ".part")

    #If a partial file exists, we will try to resume from this position.
    resume_pos = temp_path.stat().st_size if temp_path.exists() else 0

    #Get total size (if the server provides Content-Length).
    total_size = get_remote_size(url)

    #Build headers: only set Range if we can actually resume.
    headers = {}
    if total_size and resume_pos and resume_pos < total_size:
        headers["Range"] = f"bytes={resume_pos}-"

    #If we’re resuming - append to file; otherwise start fresh.
    mode = "ab" if "Range" in headers else "wb"

    #Stream the response so we don’t load the entire file into memory.
    with requests.get(url, headers=headers, stream=True, timeout=60) as r:
        r.raise_for_status()
        initial = resume_pos if total_size else 0
        total   = total_size if total_size else None

        #tqdm needs an initial and a total to display a complete progress bar
        with open(temp_path, mode) as f, tqdm(total=total, initial=initial, unit="B", unit_scale=True, desc="Downloading") as pbar:
            for chunk in r.iter_content(chunk_size=chunk_size):
                if chunk:
                    f.write(chunk)
                    pbar.update(len(chunk))

    #Only rename once the whole file is written.
    temp_path.rename(dst)
    print(f"[OK] Download complete: {dst} ({dst.stat().st_size:,} bytes)")

#Run the download
download_with_resume(ZIP_URL, LOCAL_ZIP)

#Unzipping of the Dataset Zips.
import zipfile, shutil
from pathlib import Path
from tqdm.auto import tqdm

def is_within_directory(directory: Path, target: Path) -> bool:
    """Prevent zip-slip by ensuring target stays inside directory."""
    try:
        return directory.resolve() in target.resolve().parents or directory.resolve() == target.resolve()
    except Exception:
        return False

def safe_unzip(zip_path: Path, dest_dir: Path):
    """Safely extract a ZIP file to dest_dir (no path traversal)."""
    dest_dir.mkdir(parents=True, exist_ok=True)
    with zipfile.ZipFile(zip_path, 'r') as zf:
        for m in tqdm(zf.infolist(), desc=f"Extracting {zip_path.name}", unit="file"):
            target_path = dest_dir / m.filename
            if not is_within_directory(dest_dir, target_path):
                raise RuntimeError(f"Blocked unsafe path: {m.filename}")
            if m.is_dir():
                target_path.mkdir(parents=True, exist_ok=True)
            else:
                target_path.parent.mkdir(parents=True, exist_ok=True)
                with zf.open(m, 'r') as src, open(target_path, 'wb') as dst:
                    shutil.copyfileobj(src, dst)
    print(f"[OK] Extracted to: {dest_dir}")

# Unzip the main archive
safe_unzip(LOCAL_ZIP, DEST_DIR)

"""
    This code block unzips an archive safely into a destination folder, with a progress bar and without loading the whole files into RAM.
    It performs a security check - before writing each file, it verifies the target path is inside the destination directory.
    It loops over all entries in the ZIP, creates any needed folders, then streams each file from the archive to disk.
"""
#zipfile is a standard library module to read ZIP archives; shutil is used to prevent files from loading into the RAM.
import zipfile, shutil

#Provides object-oriented file paths and makes it easy to resolve absolute paths and join paths safely.
from pathlib import Path

#progress bars.
from tqdm.auto import tqdm

#Root where inner zips live (we'll search recursively from DEST_DIR)
SEARCH_ROOT = DEST_DIR

#Temp extraction on VM (fast). Will be cleaned as we go.
TMP_ROOT = Path("/content/tmp_extract_inner")
TMP_ROOT.mkdir(parents=True, exist_ok=True)

def safe_extract_all(zf: zipfile.ZipFile, dest_dir: Path):
    #Extracts all members safely into dest_dir.
    dest_dir.mkdir(parents=True, exist_ok=True)
    for m in zf.infolist():
        target_path = dest_dir / m.filename
        if not is_within_directory(dest_dir, target_path):
            raise RuntimeError(f"Blocked unsafe path: {m.filename}")
        if m.is_dir():
            target_path.mkdir(parents=True, exist_ok=True)
        else:
            target_path.parent.mkdir(parents=True, exist_ok=True)
            with zf.open(m, 'r') as src, open(target_path, 'wb') as dst:
                shutil.copyfileobj(src, dst)

def move_all(src: Path, dst: Path):
    #Move all children of src into dst (merge/overwrite if needed).
    dst.mkdir(parents=True, exist_ok=True)
    for item in src.iterdir():
        target = dst / item.name
        if target.exists():
            if target.is_dir() and item.is_dir():
                #merge directories
                for child in item.iterdir():
                    shutil.move(str(child), str(target / child.name))
                item.rmdir()
                continue
            #remove existing and replace
            if target.is_dir():
                shutil.rmtree(target)
            else:
                target.unlink()
        shutil.move(str(item), str(target))

#Find all zip files recursively (inner/class zips)
inner_zips = sorted([p for p in SEARCH_ROOT.rglob("*.zip") if p.is_file()])
print(f"Found {len(inner_zips)} inner zip(s) under {SEARCH_ROOT}")

for zip_path in tqdm(inner_zips):
    #Desired final folder: same name as the zip (without .zip), in the same parent
    final_dir = zip_path.with_suffix("")
    tmp_dir   = TMP_ROOT / final_dir.name

    #Clean temp and extract there first
    if tmp_dir.exists():
        shutil.rmtree(tmp_dir)
    tmp_dir.mkdir(parents=True, exist_ok=True)

    with zipfile.ZipFile(zip_path, 'r') as zf:
        safe_extract_all(zf, tmp_dir)

    #If the zip contains a single top-level folder, flatten it.
    children = [c for c in tmp_dir.iterdir()]
    inner_root = children[0] if (len(children) == 1 and children[0].is_dir()) else tmp_dir

    #Move everything up to the final_dir (merge/overwrite safe)
    move_all(inner_root, final_dir)

    #Cleanup temp and remove the original zip to save space
    shutil.rmtree(tmp_dir, ignore_errors=True)
    try:
        zip_path.unlink()
    except Exception as e:
        print(f"[WARN] Could not delete {zip_path}: {e}")

    print(f"[OK] {zip_path.name} → {final_dir} (flattened)")

print("All inner zips extracted, flattened, and removed.")

from pathlib import Path

#Provides a summary to double-check what was extracted, if there are any top-level folders and what is the approximate size of the data.
def summarize_directory(root: Path):
    """Lightweight summary: class folders, file/image counts, size."""
    IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}
    n_files = 0
    n_images = 0
    total_bytes = 0
    for p in root.rglob("*"):
        if p.is_file():
            n_files += 1
            total_bytes += p.stat().st_size
            if p.suffix.lower() in IMG_EXTS:
                n_images += 1
    top = [p.name for p in root.iterdir() if p.is_dir()]
    print("—"*60)
    print(f"[SUMMARY] Root: {root}")
    print(f"Top-level folders (first 20): {top[:20]}{' ...' if len(top) > 20 else ''}")
    print(f"Total files: {n_files:,} | Image files: {n_images:,}")
    print(f"Approx size: {total_bytes/1e9:.2f} GB")
    print("—"*60)

summarize_directory(DEST_DIR)

#Check if the Dataset .zip was deleted.
try:
    LOCAL_ZIP.unlink()
    print(f"[OK] Deleted local zip: {LOCAL_ZIP}")
except FileNotFoundError:
    pass

"""# 2. Exploratory Data Analysis.

2.1. Imports, Paths and Helper Methods.
"""

#Installation of needed packages and libraries.
from pathlib import Path #to operate safely with paths on OS level.
import os, re, random, math

"""
   os to make folders, read environmental variables, list directories, set NumPy/torch thread counts, etc.;
   re to manipulate regular expressions for parsing strings and to extract PatientIDs from filenames;
   random - a randomiser for quick sampling, shuffling and seeding;
   math helpers used in cosine learning-rate schedules and small numeric utilities;
"""

from collections import Counter, defaultdict #lightweight data counters and dicts with defaults.
import numpy as np #Numerical arrays and fast ops. Used to hold images as arrays, compute statistics (means/std), Laplacian/HP measures, thresholds, etc.
import pandas as pd #Tabular dataframes for EDA/manifests. To store filepaths, class labels, patient IDs, blur scores, etc.
import cv2 #OpenCV for image I/O and processing.
import matplotlib.pyplot as plt #Used for plotting.
from tqdm.auto import tqdm #For progress bars.


#PATHS CONFIGURATION
DATA_ROOT = Path("/content/drive/MyDrive/AI/Project_Summer_Module/Gallblader Diseases Dataset") #Root Directory of the dataset. CHANGE if you are running on your own machine.
EDA_OUT   = DATA_ROOT / "eda_outputs" #Setting the Output directory for the outputs of the EDA.
EDA_OUT.mkdir(parents=True, exist_ok=True) #Create the folder if it does not exist.

print(f"[OK] DATA_ROOT: {DATA_ROOT} | exists={DATA_ROOT.exists()}")
print(f"[OK] EDA_OUT:   {EDA_OUT}")


#IMAGE HELPERS
#Acceptable image extensions
IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}

#Returns True if p is a regular file with a known image extension.
def is_image(p: Path) -> bool:
    return p.is_file() and p.suffix.lower() in IMG_EXTS


#Robust grayscale reader that copes with non-ASCII paths.Returns a uint8 grayscale image or None on failure.
def safe_imread_gray(path: str | Path):

    path = str(path)
    try:
        arr = np.fromfile(path, dtype=np.uint8)
        img = cv2.imdecode(arr, cv2.IMREAD_GRAYSCALE)
        if img is None:
            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        return img
    except Exception:
        return None

#Focus measure used for blur QC: higher = sharper.
def variance_of_laplacian(gray_img: np.ndarray) -> float:
    return float(cv2.Laplacian(gray_img, cv2.CV_64F).var())

#Used later for letterbox/resize in preprocessing & VoL scoring
def letterbox_square(img_gray: np.ndarray, pad_value: int = 0):
    """
    Pad a grayscale image to a square canvas while keeping content centered.
    Returns (square_image, (top, bottom, left, right)).
    """
    h, w = img_gray.shape[:2]
    side = max(h, w)
    top    = (side - h) // 2
    bottom = side - h - top
    left   = (side - w) // 2
    right  = side - w - left
    img_sq = cv2.copyMakeBorder(img_gray, top, bottom, left, right,
                                borderType=cv2.BORDER_CONSTANT, value=pad_value)
    return img_sq, (top, bottom, left, right)


#PATIENT ID EXTRACTION
def guess_patient_id_v2(filename: str) -> str | None:
    """
    Heuristic parser for filenames like: 'a31 (16).jpg', 'a6 (44).jpg', 'a32 (225).jpg'
    Priority:
      1) letters+digits at the VERY START (e.g., 'a31', 'pat123')  -> 'a31'
      2) digits+letters at the start      (e.g., '12a')            -> '12a'
      3) fallback: token before first space or '('                 -> 'a31'
    Returns a lowercase token or None if nothing sensible is found.
    """
    stem = Path(filename).stem.strip()
    s = stem.replace('_', ' ').replace('-', ' ')

    #1. letters+digits at start
    m = re.match(r'^([A-Za-z]+[0-9]+)', s)
    if m:
        return m.group(1).lower()

    #2. digits+letters at start
    m = re.match(r'^([0-9]+[A-Za-z]+)', s)
    if m:
        return m.group(1).lower()

    #3. fallback token before space or (
    token = re.split(r'[ \(]', s, maxsplit=1)[0].strip()
    return token.lower() if token else None


#(Optional) QUICK HELPERS THAT MIGHT BE USED IN LATER CELLS.
#Returns sorted list of immediate subfolders (each expected to be a class).
def discover_class_dirs(root: Path) -> list[Path]:
    class_dirs = [d for d in root.iterdir() if d.is_dir()]
    class_dirs = sorted(class_dirs, key=lambda p: p.name)
    return class_dirs

#Fast width/height/aspect reader (no full decode to RGB). Returns (width, height, aspect) or (None, None, None) if failed.
def image_geometry(path: str | Path):
    path = str(path)
    try:
        arr = np.fromfile(path, dtype=np.uint8)
        img = cv2.imdecode(arr, cv2.IMREAD_UNCHANGED)
        if img is None:
            img = cv2.imread(path, cv2.IMREAD_UNCHANGED)
        if img is None:
            return None, None, None
        h, w = img.shape[:2]
        return int(w), int(h), (float(w) / float(h) if h else None)
    except Exception:
        return None, None, None

print("[READY] Helpers loaded: is_image, safe_imread_gray, variance_of_laplacian, letterbox_square, guess_patient_id_v2, image_geometry")

"""2.2. Discover dataset structure and collect file list.



"""

#Uses helpers from the previous cell: discover_class_dirs, is_image, image_geometry, guess_patient_id_v2

#Used to count how many times each item appears in a list or sequence.
from collections import Counter

#1. Find class folders (each immediate subdir is treated as a class)
class_dirs = discover_class_dirs(DATA_ROOT)
print(f"Found {len(class_dirs)} class folders:")
for d in class_dirs:
    print("  •", d.name)

#2. Build a manifest of all images
rows = []
for cdir in class_dirs:
    cname = cdir.name
    for imgp in cdir.rglob("*"):
        if not is_image(imgp):
            continue
        w, h, asp = image_geometry(imgp)
        rows.append({
            "filepath": str(imgp),
            "class": cname,
            "filename": imgp.name,
            "patient_id": guess_patient_id_v2(imgp.name),  #robust patient ID
            "width": w, "height": h, "aspect": asp,
        })

df_all = pd.DataFrame(rows).sort_values(["class", "filename"]).reset_index(drop=True)
print(f"\nTotal images discovered: {len(df_all):,}")

#3. Class index mapping (stable order = alphabetical by folder name)
class_to_idx = {d.name: i for i, d in enumerate(class_dirs)}
idx_to_class = {i: c for c, i in class_to_idx.items()}
df_all["class_idx"] = df_all["class"].map(class_to_idx)

#4. Quick reports
print("\nClass counts:")
display(df_all["class"].value_counts())

coverage = df_all["patient_id"].notna().mean()
print(f"[patient_id] coverage: {coverage*100:.1f}%  "
      f"({df_all['patient_id'].notna().sum()} / {len(df_all)})")

#Peek at a few unresolved cases, if any
unresolved = df_all[df_all["patient_id"].isna()].head(10)
if len(unresolved):
    print("\n[Examples with None patient_id] — eyeball these to refine the regex if needed:")
    display(unresolved[["filename", "class"]])

#5. Save the manifest for later steps (splits, QC, etc.)
idx_csv = EDA_OUT / "image_index.csv"
df_all.to_csv(idx_csv, index=False)
print(f"\n[OK] Saved image index to: {idx_csv}")

#6. Preview
display(df_all.head(10))

"""2.3. Basic counts: classes, (guessed) patients, top structure"""

#Safety checks
try:
    _ = df_all
except NameError:
    raise SystemExit("df_all is not defined. Run Cell 2 first to build the file list.")

if len(df_all) == 0:
    raise SystemExit("No images found; cannot continue EDA.")

#Class counts
class_counts = df_all["class"].value_counts().sort_values(ascending=False)
n_classes = class_counts.shape[0]
print(f"Classes detected: {n_classes}")
display(class_counts)

#Patient coverage and counts (using robust patient_id)
coverage = df_all["patient_id"].notna().mean()
n_patients = df_all["patient_id"].nunique(dropna=True)
print(f"[patient_id] coverage: {coverage*100:.1f}%  ({df_all['patient_id'].notna().sum()} / {len(df_all)})")
print(f"Distinct patients (guessed): {n_patients}")

patient_counts = df_all["patient_id"].value_counts(dropna=True).sort_values(ascending=False)

#Save summaries
(class_counts).to_csv(EDA_OUT / "class_counts.csv")
(patient_counts).to_csv(EDA_OUT / "patient_counts_guess.csv")

#Plot class distribution
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 4 + 0.2 * n_classes))
class_counts.plot(kind="barh")
plt.gca().invert_yaxis()
plt.title("Class distribution")
plt.xlabel("Number of images")
plt.tight_layout()
plt.savefig(EDA_OUT / "class_distribution.png", dpi=220)
plt.show()

#Quick top-level structure under DATA_ROOT
top_entries = [p.name for p in DATA_ROOT.iterdir()]
print("Top-level entries under DATA_ROOT:", top_entries[:30], "..." if len(top_entries) > 30 else "")

"""2.4. Image geometry: sizes, aspect ratios, grayscale check"""

#Safety check: make sure df_all exists
try:
    _ = df_all
except NameError:
    raise SystemExit("df_all is not defined. Run Cell 2 first.")

if len(df_all) == 0:
    raise SystemExit("No images found; cannot continue EDA.")

#If any geometry is missing, compute it now using image_geometry()
geom_cols = ["width", "height", "aspect"]
missing_mask = df_all[geom_cols].isna().any(axis=1)

if missing_mask.any():
    print(f"[INFO] Filling geometry for {missing_mask.sum()} images with missing width/height/aspect...")
    widths, heights, aspects = [], [], []
    for fp in tqdm(df_all.loc[missing_mask, "filepath"], desc="Computing geometry", unit="img"):
        w, h, asp = image_geometry(fp)
        widths.append(w); heights.append(h); aspects.append(asp)
    df_all.loc[missing_mask, "width"]  = widths
    df_all.loc[missing_mask, "height"] = heights
    df_all.loc[missing_mask, "aspect"] = aspects

#Describe geometry
geom_df = df_all[geom_cols].dropna().astype(float)
display(geom_df.describe(percentiles=[0.05, 0.50, 0.95]))

#Plots: width, height, aspect ratio
import matplotlib.pyplot as plt
plt.rcParams["figure.dpi"] = 140

fig, ax = plt.subplots(1, 3, figsize=(14, 3.8))
ax[0].hist(geom_df["width"], bins=30)
ax[0].set_title("Width distribution")
ax[0].set_xlabel("pixels")

ax[1].hist(geom_df["height"], bins=30)
ax[1].set_title("Height distribution")
ax[1].set_xlabel("pixels")

ax[2].hist(geom_df["aspect"], bins=30)
ax[2].set_title("Aspect ratio (W/H)")
ax[2].set_xlabel("ratio")

for a in ax:
    a.set_ylabel("Count")

plt.tight_layout()
plt.savefig(EDA_OUT / "geometry_distributions.png", dpi=220)
plt.show()

#Quick grayscale vs 3-channel probe (sample)
from collections import Counter
import numpy as np
import cv2

def detect_channels(fp: str) -> int | None:
    arr = np.fromfile(fp, dtype=np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_UNCHANGED)
    if img is None:
        img = cv2.imread(fp, cv2.IMREAD_UNCHANGED)
    if img is None:
        return None
    if img.ndim == 2:    # H x W
        return 1
    return int(img.shape[2])  # H x W x C

SAMPLE_N = min(1000, len(df_all))
sample_paths = df_all["filepath"].sample(SAMPLE_N, random_state=42)

chan_counts = Counter()
skipped = 0
for fp in tqdm(sample_paths, desc="Channel probe", unit="img"):
    c = detect_channels(fp)
    if c is None:
        skipped += 1
        continue
    chan_counts[c] += 1

print(f"[Channels] Sampled {SAMPLE_N} images (skipped {skipped}).")
for k, v in sorted(chan_counts.items()):
    label = "grayscale (1 ch)" if k == 1 else f"{k}-channel"
    print(f"  {label}: {v}")

#Save updated df_all with geometry (if it changed)
df_all.to_csv(EDA_OUT / "image_index.csv", index=False)
print(f"[OK] geometry_distributions.png saved; image_index.csv refreshed at: {EDA_OUT / 'image_index.csv'}")

"""2.5. Blur distribution (Variance-of-Laplacian) + suggested threshold"""

#Uses helpers from Cell 1: safe_imread_gray, letterbox_square, variance_of_laplacian
import numpy as np #for saving pictures in arrays, calculations, etc.
import matplotlib.pyplot as plt #to plot graphs
from tqdm.auto import tqdm #for progress bars

#Safety
try:
    _ = df_all
except NameError:
    raise SystemExit("df_all is not defined. Run Cell 2 first to build the file list.")

if len(df_all) == 0:
    raise SystemExit("No images found; cannot continue EDA.")

TARGET_SIZE = 320

#Load grayscale, letterbox to square, resize to 320x320, return VoL score.
def vol_score_at_320(fp: str) -> float | None:

    g = safe_imread_gray(fp)
    if g is None:
        return None
    g_sq, _ = letterbox_square(g, pad_value=0)
    g_320 = cv2.resize(g_sq, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_LINEAR)
    return variance_of_laplacian(g_320)


#Compute VoL over a (possibly sampled) list of filepaths. Returns np.array of scores (floats). Skips unreadable images.
def compute_vol_distribution(filepaths, max_samples=None, seed=42):
    rng = np.random.default_rng(seed)
    fps = list(filepaths)
    if max_samples and len(fps) > max_samples:
        fps = list(rng.choice(fps, size=max_samples, replace=False))
    scores = []
    skipped = 0
    for fp in tqdm(fps, desc="VoL scoring @320×320", unit="img"):
        s = vol_score_at_320(fp)
        if s is None:
            skipped += 1
            continue
        scores.append(s)
    scores = np.array(scores, dtype=np.float64)
    print(f"[VoL] Scored: {len(scores)} images  |  Skipped: {skipped}")
    return scores

#Run on all images (set MAX_VOL_SAMPLES to e.g. 6000 for speed if needed)
MAX_VOL_SAMPLES = None  # or e.g., 6000
vol_scores = compute_vol_distribution(df_all["filepath"].tolist(), max_samples=MAX_VOL_SAMPLES)

#Save raw scores for the thesis appendix
(vol_scores.astype(np.float64)).tofile(str(EDA_OUT / "vol_scores.bin"))
np.savetxt(str(EDA_OUT / "vol_scores.csv"), vol_scores, fmt="%.6f", delimiter=",")

#Suggested thresholds (dataset-wide preview; per-fold thresholds later)
p5, p8, p10 = np.percentile(vol_scores, [5, 8, 10])
print("Suggested VoL thresholds (dataset-wide; we will recompute per train fold):")
print(f"  τ_5%  = {p5:.2f}")
print(f"  τ_8%  = {p8:.2f}")
print(f"  τ_10% = {p10:.2f}")

#Set a provisional working threshold (used only for exploratory EDA now)
VOL_THRESHOLD = float(p8)
print(f"[SET] Provisional blur threshold τ = {VOL_THRESHOLD:.2f} (8th percentile)")

#Plot distribution
plt.figure(figsize=(8, 3.6))
plt.hist(vol_scores, bins=60)
plt.axvline(p8, color="r", linestyle="--", label=f"8th pct = {p8:.1f}")
plt.title("Variance of Laplacian (VoL) distribution @ 320×320")
plt.xlabel("VoL (higher = sharper)")
plt.ylabel("Count")
plt.legend()
plt.tight_layout()
plt.savefig(EDA_OUT / "vol_distribution.png", dpi=220)
plt.show()

print(f"[OK] Saved: {EDA_OUT / 'vol_scores.csv'} and {EDA_OUT / 'vol_distribution.png'}")

"""2.6. Per-class random montages (quick visual audit)"""

#Builds one grid image per class so you can eyeball variability/artefacts.
#Uses: df_all (from Cell 2), EDA_OUT, safe_imread_gray (from Cell 1)

import numpy as np #for faster math. operations, storing of images as arrays, etc.
import matplotlib.pyplot as plt #for plotting
import re #Tools for working with text using regular expressions.
from pathlib import Path #to work with paths on OS level.
from tqdm.auto import tqdm #for progress bars.

plt.rcParams["figure.dpi"] = 140

#Center-crop a grayscale image to a square (min(H, W)).
def center_square_crop(img: np.ndarray) -> np.ndarray:
    h, w = img.shape[:2]
    side = min(h, w)
    y0 = (h - side) // 2
    x0 = (w - side) // 2
    return img[y0:y0+side, x0:x0+side]

"""
Create and save a montage for a given class.
- n_rows x n_cols tiles
- grayscale center-crop → resize to tile_size
Returns saved path or None if no images could be read.
"""
def save_class_montage(class_name: str,
                       df_class,
                       n_rows: int = 3,
                       n_cols: int = 5,
                       tile_size: int = 128,
                       seed: int = 42) -> Path | None:
    rng = np.random.default_rng(seed)
    max_tiles = n_rows * n_cols

    #Sample without replacement (or take all if class is small)
    filepaths = df_class["filepath"].to_numpy()
    if len(filepaths) == 0:
        return None
    if len(filepaths) > max_tiles:
        idx = rng.choice(len(filepaths), size=max_tiles, replace=False)
        filepaths = filepaths[idx]

    tiles = []
    for fp in filepaths:
        g = safe_imread_gray(fp)
        if g is None:
            continue
        g_sq = center_square_crop(g)
        g_res = cv2.resize(g_sq, (tile_size, tile_size), interpolation=cv2.INTER_AREA)
        tiles.append(g_res)

    if len(tiles) == 0:
        print(f"[WARN] Could not read any images for class '{class_name}'.")
        return None

    #Prepare canvas
    H = n_rows * tile_size
    W = n_cols * tile_size
    canvas = np.zeros((H, W), dtype=np.uint8)

    #Paste tiles row by row
    for i, img in enumerate(tiles[:max_tiles]):
        r = i // n_cols
        c = i % n_cols
        canvas[r*tile_size:(r+1)*tile_size, c*tile_size:(c+1)*tile_size] = img

    #Save figure
    fig = plt.figure(figsize=(n_cols*1.6, n_rows*1.6))
    plt.imshow(canvas, cmap="gray")
    plt.axis("off")
    plt.title(f"{class_name}  |  n={len(df_class)}", fontsize=11, pad=6)

    #Safe filename
    safe_name = re.sub(r"[^A-Za-z0-9._-]+", "_", class_name)
    out_path = EDA_OUT / f"montage_{safe_name}.png"
    plt.savefig(out_path, dpi=220, bbox_inches="tight", pad_inches=0.05)
    plt.show()
    plt.close(fig)
    return out_path

#Build montages for top-k classes (by count)
class_counts = df_all["class"].value_counts()
top_k = min(len(class_counts), 9)  #change if you want more/less
targets = class_counts.index[:top_k].tolist()

saved = []
for cname in tqdm(targets, desc="Montages"):
    df_c = df_all[df_all["class"] == cname]
    p = save_class_montage(cname, df_c, n_rows=3, n_cols=5, tile_size=128, seed=42)
    if p is not None:
        saved.append(p)

print("\n[OK] Saved montages:")
for p in saved:
    print("  •", p)

"""2.7. Save a clean EDA report CSV"""

#Consolidates key fields into a single CSV and writes summary files.

import json
import numpy as np

#Safety
try:
    _ = df_all
except NameError:
    raise SystemExit("df_all is not defined. Run Cell 2 first.")

if len(df_all) == 0:
    raise SystemExit("No images found; cannot continue EDA.")

#1. Clean report with stable column order
cols_order = ["filepath", "filename", "class", "class_idx", "patient_id", "width", "height", "aspect"]
missing = [c for c in cols_order if c not in df_all.columns]
if missing:
    raise ValueError(f"Missing expected columns in df_all: {missing}")

df_report = df_all[cols_order].copy()
df_report.sort_values(["class", "patient_id", "filename"], inplace=True)

report_csv = EDA_OUT / "eda_report.csv"
df_report.to_csv(report_csv, index=False)
print(f"[OK] EDA report saved to: {report_csv}")

#2. Per-class and per-patient counts
class_counts = df_all["class"].value_counts().sort_values(ascending=False)
patient_counts = df_all["patient_id"].value_counts().sort_values(ascending=False)

class_counts.to_csv(EDA_OUT / "class_counts.csv")
patient_counts.to_csv(EDA_OUT / "patient_counts.csv")
print(f"[OK] Saved class_counts.csv and patient_counts.csv")

#3. Compact JSON summary (nice for the thesis appendix / reproducibility)
summary = {
    "n_images": int(len(df_all)),
    "n_classes": int(df_all["class"].nunique()),
    "n_patients": int(df_all["patient_id"].nunique()),
    "image_width_mean": float(np.nanmean(df_all["width"])),
    "image_height_mean": float(np.nanmean(df_all["height"])),
    "aspect_mean": float(np.nanmean(df_all["aspect"])),
    "aspect_p5_p95": [
        float(np.nanpercentile(df_all["aspect"].dropna(), 5)),
        float(np.nanpercentile(df_all["aspect"].dropna(), 95)),
    ],
}

#If VoL scores were computed in Cell 5, include suggested thresholds here too
vol_csv = EDA_OUT / "vol_scores.csv"
if vol_csv.exists():
    try:
        vol_scores = np.loadtxt(vol_csv, delimiter=",")
        if vol_scores.size > 0:
            summary["vol_thresholds"] = {
                "p5": float(np.percentile(vol_scores, 5)),
                "p8": float(np.percentile(vol_scores, 8)),
                "p10": float(np.percentile(vol_scores, 10)),
            }
    except Exception as e:
        print(f"[WARN] Could not load vol_scores.csv: {e}")

with open(EDA_OUT / "eda_summary.json", "w") as f:
    json.dump(summary, f, indent=2)
print(f"[OK] Wrote eda_summary.json to: {EDA_OUT}")

#4. Preview first few rows
display(df_report.head(10))

"""# 3. Pre-processing and Quality Check.

3.1. Config & reproducibility
"""

#Import Needed libraries.
import os, random
import numpy as np
import torch

#Core config
IMG_SIZE = 320
VOL_PERCENTILE = 8.0   #blur threshold percentile for train filtering
MEDIAN_FILTER = True   #apply 3x3 median denoise
BATCH_SIZE = 32
NUM_WORKERS = 2        #adjust to between 2-4.

#Repro seeding
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

#Make CuDNN behavior deterministic (slower but reproducible)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

print(f"[CFG] IMG_SIZE={IMG_SIZE}, VOL_PERCENTILE={VOL_PERCENTILE}, MEDIAN_FILTER={MEDIAN_FILTER}")

"""3.2. Albumentations pipelines (train vs eval)."""

#Import Needed libraries.

#Restricting the environment to certain versions due to deprications in the latest ones or errors.
!pip -q install albumentations==1.4.4 opencv-python==4.9.0.80

import albumentations as A
from albumentations.pytorch import ToTensorV2

#Definition of Z-score function.
class PerImageZScore(A.ImageOnlyTransform):
    """Per-image z-score: (x - mean) / std, applied after photometric augs."""
    def __init__(self, p=1.0, eps=1e-6):
        super().__init__(always_apply=True, p=p)
        self.eps = eps
    def apply(self, img, **params):
        img = img.astype(np.float32)
        mu = img.mean()
        sigma = img.std()
        sigma = max(sigma, self.eps)
        return (img - mu) / sigma

def make_train_transform():
    return A.Compose([
        #photometric + geometric (small, conservative)
        A.HorizontalFlip(p=0.5),
        A.ShiftScaleRotate(shift_limit=0.0, scale_limit=0.10, rotate_limit=10,
                           border_mode=cv2.BORDER_CONSTANT, p=0.8),
        A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.8),
        #standardise after augs
        PerImageZScore(p=1.0),
        ToTensorV2(),
    ])

def make_eval_transform():
    return A.Compose([
        PerImageZScore(p=1.0),
        ToTensorV2(),
    ])

train_tf = make_train_transform()
eval_tf  = make_eval_transform()

print("[OK] Transforms ready (train vs eval).")

"""3.3 PyTorch Dataset with preprocessing stages."""

#Reuses: safe_imread_gray, letterbox_square, median_3x3, to_rgb3_from_gray (from earlier)

#Function to transform 1-channel (gray) to 3-channels (RGB)
def to_rgb3_from_gray(img_gray: np.ndarray):
    """Stack gray to 3 channels (RGB order)."""
    return cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)

#Function for Blur filtering.
def median_3x3(img_gray: np.ndarray):
    return cv2.medianBlur(img_gray, 3)

from torch.utils.data import Dataset, DataLoader

class GBDDataset(Dataset):
    """
    Pipeline (per sample):
      1) read grayscale
      2) letterbox to square
      3) resize to IMG_SIZE
      4) optional 3x3 median denoise
      5) convert to RGB
      6) Albumentations (train or eval)
      7) return tensor, label, filepath
    """
    def __init__(self, df, class_to_idx: dict, transform: A.Compose,
                 img_size: int = 320, use_median: bool = True):
        self.df = df.reset_index(drop=True)
        self.class_to_idx = class_to_idx
        self.transform = transform
        self.img_size = img_size
        self.use_median = use_median

    def __len__(self):
        return len(self.df)

    def __getitem__(self, i):
        row = self.df.iloc[i]
        fp = row.filepath
        label = self.class_to_idx[row["class"]]

        #1. read grayscale
        g = safe_imread_gray(fp)
        if g is None:
            raise RuntimeError(f"Failed to read image: {fp}")

        #2. letterbox to square
        g_sq, _ = letterbox_square(g, pad_value=0)

        #3. resize
        g_rz = cv2.resize(g_sq, (self.img_size, self.img_size), interpolation=cv2.INTER_LINEAR)

        #4. optional median denoise
        if self.use_median:
            g_rz = median_3x3(g_rz)

        #5. to rgb
        rgb = to_rgb3_from_gray(g_rz)  # uint8, HWC

        #6. albumentations
        aug = self.transform(image=rgb)
        img_t = aug["image"]  # CHW float tensor

        return img_t, int(label), fp

"""3.4 Blur QC utilities (VoL threshold on train only)"""

def vol_score_at_size(fp: str, size: int = IMG_SIZE) -> float | None:
    """Load gray → letterbox → resize → VoL."""
    g = safe_imread_gray(fp)
    if g is None:
        return None
    g_sq, _ = letterbox_square(g, pad_value=0)
    g_rz = cv2.resize(g_sq, (size, size), interpolation=cv2.INTER_LINEAR)
    return variance_of_laplacian(g_rz)

def compute_vol_scores(filepaths, max_samples=None, seed=SEED):
    """Compute VoL scores for a list of filepaths; optionally subsample for speed."""
    rng = np.random.default_rng(seed)
    fps = list(filepaths)
    if max_samples and len(fps) > max_samples:
        fps = list(rng.choice(fps, size=max_samples, replace=False))
    scores = []
    skipped = 0
    for fp in tqdm(fps, desc="VoL", unit="img"):
        s = vol_score_at_size(fp, size=IMG_SIZE)
        if s is None:
            skipped += 1
            continue
        scores.append(s)
    scores = np.array(scores, dtype=np.float64)
    print(f"[VoL] Scored={len(scores)} | Skipped={skipped}")
    return scores

def choose_threshold_from_train(train_df, percentile: float = VOL_PERCENTILE):
    """Choose τ from the train pool only (e.g., 8th percentile)."""
    scores = compute_vol_scores(train_df["filepath"].tolist(), max_samples=None)
    tau = float(np.percentile(scores, percentile))
    return tau, scores

def filter_train_by_blur(train_df, tau: float, log_dir: Path):
    """
    Keep only images with VoL >= tau.
    Writes CSVs of kept/dropped for reproducibility.
    """
    keep_mask = []
    kept_rows, dropped_rows = [], []
    for _, row in tqdm(train_df.iterrows(), total=len(train_df), desc="QC filter", unit="img"):
        s = vol_score_at_size(row.filepath, size=IMG_SIZE)
        ok = (s is not None) and (s >= tau)
        keep_mask.append(ok)
        (kept_rows if ok else dropped_rows).append({**row.to_dict(), "vol": None if s is None else float(s)})

    kept_df = pd.DataFrame(kept_rows).reset_index(drop=True)
    dropped_df = pd.DataFrame(dropped_rows).reset_index(drop=True)

    log_dir.mkdir(parents=True, exist_ok=True)
    kept_df.to_csv(log_dir / "train_kept_after_blur.csv", index=False)
    dropped_df.to_csv(log_dir / "train_dropped_blur.csv", index=False)

    print(f"[QC] Kept {len(kept_df):,} | Dropped {len(dropped_df):,} (τ={tau:.2f})")
    return kept_df, dropped_df

"""3.5 Example: dev/test split, then apply blur QC to train only, then build DataLoaders"""

#Installation of needed libraries.

from sklearn.model_selection import StratifiedShuffleSplit

#Safety: needs df_all and class_to_idx from EDA Cell 2
try:
    _ = df_all, class_to_idx
except NameError:
    raise SystemExit("Run EDA Cell 2 first (it defines df_all and class_to_idx).")

#(Demo) stratified image-level split 85/15 (we'll replace with patient-level CV later)
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=SEED)
y = df_all["class"].map(class_to_idx).values
tr_idx, te_idx = next(sss.split(df_all, y))
df_dev  = df_all.iloc[tr_idx].reset_index(drop=True)
df_test = df_all.iloc[te_idx].reset_index(drop=True)
print(f"Dev={len(df_dev):,} | Test={len(df_test):,}")

#Choose blur threshold tau from DEV (train pool)
QC_LOG_DIR = (EDA_OUT / "qc_demo")
tau, scores = choose_threshold_from_train(df_dev, percentile=VOL_PERCENTILE)
print(f"[QC] τ (p{VOL_PERCENTILE:.0f}) = {tau:.2f}")

#Filter DEV by tau (train only); Test remains untouched
df_train_qc, df_train_dropped = filter_train_by_blur(df_dev, tau=tau, log_dir=QC_LOG_DIR)

#Build Datasets
train_ds = GBDDataset(df_train_qc, class_to_idx, transform=train_tf,
                      img_size=IMG_SIZE, use_median=MEDIAN_FILTER)
test_ds  = GBDDataset(df_test,      class_to_idx, transform=eval_tf,
                      img_size=IMG_SIZE, use_median=MEDIAN_FILTER)

#DataLoaders
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,
                          num_workers=NUM_WORKERS, pin_memory=True)
test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,
                          num_workers=NUM_WORKERS, pin_memory=True)

#Peek at one batch
xb, yb, fps = next(iter(train_loader))
print("Train batch:", xb.shape, yb.shape, "| dtype", xb.dtype)
print("Classes in this batch:", sorted(set(yb.tolist())))

"""3.6 Visual sanity check: original to preprocessed to augmented"""

#Install needed packages and libraries.

import matplotlib.pyplot as plt

def show_sample(df_row, transform):
    g = safe_imread_gray(df_row.filepath)
    g_sq, _ = letterbox_square(g, pad_value=0)
    g_rz = cv2.resize(g_sq, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)
    if MEDIAN_FILTER:
        g_rz = median_3x3(g_rz)
    rgb = to_rgb3_from_gray(g_rz)

    #Apply transform once (e.g., train_tf with augs)
    out = transform(image=rgb)["image"]
    #convert to HWC for plotting
    out_np = out.permute(1, 2, 0).cpu().numpy()
    #undo z-score for display (min-max to 0-1 for quick view)
    out_disp = (out_np - out_np.min()) / (out_np.max() - out_np.min() + 1e-6)

    fig, ax = plt.subplots(1, 2, figsize=(8, 4))
    ax[0].imshow(rgb, cmap=None)
    ax[0].set_title("Preprocessed (RGB)"); ax[0].axis("off")
    ax[1].imshow(out_disp, cmap=None)
    ax[1].set_title("After augs + z-score"); ax[1].axis("off")
    plt.show()

#Try it on a random kept training image
if len(df_train_qc):
    show_sample(df_train_qc.sample(1, random_state=SEED).iloc[0], transform=train_tf)

"""# 4. Splitting and Test Validation

4.1. Config & load manifest.
"""

#Importing of Libraries and Packages that are needed.
from pathlib import Path
import os, json, hashlib
import numpy as np
import pandas as pd
import cv2
from tqdm.auto import tqdm

#PATHS
PROJ_ROOT   = Path("/content/drive/MyDrive/AI/Project_Summer_Module") #Setting up of the root folder where the project is situated. CHANGE if you are running the code on your machine.
DATA_ROOT   = PROJ_ROOT / "Gallblader Diseases Dataset"   #your class folders
EDA_OUT     = DATA_ROOT / "eda_outputs"                   #setting the path for the EDA output
CACHE_ROOT  = PROJ_ROOT / "cache_320_rgb_v1"              #preprocessed images (RGB 320x320)
SPLITS_ROOT = PROJ_ROOT / "splits_5fold_v1"               #CSVs + metadata

CACHE_ROOT.mkdir(parents=True, exist_ok=True)
SPLITS_ROOT.mkdir(parents=True, exist_ok=True)

#PREPROCESSING SETTINGS
IMG_SIZE          = 320
USE_MEDIAN        = True          # apply 3×3 median denoise
VOL_PERCENTILE    = 8.0           # per-train-fold tau (VoL) percentile
SEED              = 42

#Load manifest from EDA (or fallback to df_all if still in memory)
manifest_csv = EDA_OUT / "eda_report.csv"
if manifest_csv.exists():
    df_all = pd.read_csv(manifest_csv)
    print(f"[OK] Loaded manifest: {manifest_csv}  (rows={len(df_all):,})")
else:
    try:
        _ = df_all
        print("[OK] Using df_all from memory (EDA not saved to CSV).")
    except NameError:
        raise SystemExit("No manifest found. Please run EDA to produce eda_outputs/eda_report.csv first.")

#Sanity: ensure columns
need_cols = {"filepath", "filename", "class", "class_idx", "patient_id"}
missing = need_cols - set(df_all.columns)
if missing:
    raise ValueError(f"Manifest missing columns: {missing}")

#Fallback: if any patient_id is NaN, assign a unique pseudo-ID (safe for grouping)
if df_all["patient_id"].isna().any():
    fill_ids = [f"img_{i}" for i in range(len(df_all))]
    df_all["patient_id"] = df_all["patient_id"].fillna(pd.Series(fill_ids, index=df_all.index))

#Helper: safe grayscale read
def safe_imread_gray(path: str):
    arr = np.fromfile(path, dtype=np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_GRAYSCALE)
    if img is None:
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    return img

#Helper: letterbox to square
def letterbox_square(img_gray: np.ndarray, pad_value=0):
    h, w = img_gray.shape[:2]
    side = max(h, w)
    top    = (side - h) // 2
    bottom = side - h - top
    left   = (side - w) // 2
    right  = side - w - left
    sq = cv2.copyMakeBorder(img_gray, top, bottom, left, right, cv2.BORDER_CONSTANT, value=pad_value)
    return sq

#Helper: variance of Laplacian
def vol(gray_img: np.ndarray) -> float:
    return float(cv2.Laplacian(gray_img, cv2.CV_64F).var())

#Safe PNG write (supports non-ASCII paths)
def imwrite_png(path: Path, img_bgr_or_rgb: np.ndarray):
    ext = ".png"
    path = path.with_suffix(ext)
    ok, enc = cv2.imencode(ext, img_bgr_or_rgb)
    if not ok:
        raise IOError(f"Failed to encode {path}")
    enc.tofile(str(path))
    return path

#IF You GET AN ERROR WITH COMPATIBILITY OF CV2 AND NUMPY RUN THIS CODE AND RESTART THE RUNTIME. RUN THE SANITY CHECK BELOW AND START AGAIN FROM 4.1.
#Clean re-pin to a stable stack for Colab
!pip -q uninstall -y opencv-python opencv-python-headless numpy
!pip -q install --upgrade --force-reinstall \
  "numpy==1.26.4" \
  "scikit-learn>=1.6.0" \
  opencv-python==4.9.0.80 \
  albumentations==1.4.4 \
  timm==0.9.12

#(Optional) silence a common IPython warning in some Colab images
!pip -q install "jedi>=0.18.0"

print("Now go to: Runtime then Restart runtime. After it restarts, run your imports again.")

#After the restart, run sanity-check imports
import numpy, cv2, sklearn, albumentations, timm, torch
print("NumPy:", numpy.__version__)          # should be 1.26.4
print("OpenCV:", cv2.__version__)           # 4.9.0.80
print("scikit-learn:", sklearn.__version__) # >=1.6
print("Albumentations:", albumentations.__version__)
print("timm:", timm.__version__)
print("Torch:", torch.__version__)

"""4.2. Cache preprocessed images (letterbox→320, median, to RGB) + VoL"""

#Build cache path: CACHE_ROOT/<class>/<filename>.png
def cache_path_for(row) -> Path:
    cls = str(row["class"])
    base = Path(row["filename"]).stem + ".png"   # unify to png
    return CACHE_ROOT / cls / base

#Process and cache (skips if already exists)
cached_paths = []
vol_scores   = []

for i, row in tqdm(df_all.iterrows(), total=len(df_all), desc="Caching 320×320"):
    src = row["filepath"]
    dst = cache_path_for(row)
    if not dst.parent.exists():
        dst.parent.mkdir(parents=True, exist_ok=True)
    if not dst.exists():
        g = safe_imread_gray(src)
        if g is None:
            print(f"[WARN] unreadable: {src}")
            cached_paths.append(None)
            vol_scores.append(np.nan)
            continue
        g_sq = letterbox_square(g, pad_value=0)
        g_rz = cv2.resize(g_sq, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)
        if USE_MEDIAN:
            g_rz = cv2.medianBlur(g_rz, 3)
        #to RGB (3ch) for backbones expecting 3 channels
        rgb = cv2.cvtColor(g_rz, cv2.COLOR_GRAY2RGB)
        try:
            imwrite_png(dst, rgb)
        except Exception as e:
            print(f"[WARN] failed to write: {dst} :: {e}")
            cached_paths.append(None)
            vol_scores.append(np.nan)
            continue
    #compute/store VoL on the cached (guaranteed 320×320 gray-equivalent)
    #Read back as gray for consistent VoL (fast)
    arr = np.fromfile(str(dst), dtype=np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_GRAYSCALE)
    v = np.nan if img is None else vol(img)
    cached_paths.append(str(dst))
    vol_scores.append(v)

df_all["cache_path"] = cached_paths
df_all["vol_320"] = vol_scores

#Save cache mapping
cache_map_csv = CACHE_ROOT / "cache_manifest.csv"
df_all.to_csv(cache_map_csv, index=False)
print(f"[OK] Wrote cache manifest: {cache_map_csv}")
print(f"[INFO] Cached ok: {(df_all['cache_path'].notna()).sum()} / {len(df_all)}")

"""4.3. Create patient-level splits: 85/15 hold-out test, then 5-fold CV on 85%"""

from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold
import numpy as np

#Ensure we only use rows that cached successfully
df_ok = df_all[df_all["cache_path"].notna()].reset_index(drop=True)
print(f"[OK] Images available for splitting: {len(df_ok):,}")

y = df_ok["class_idx"].values
groups = df_ok["patient_id"].astype(str).values

#1. Patient-level 15% hold-out TEST (group-only split; class strat is handled in CV later)
gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=SEED)
train_dev_idx, test_idx = next(gss.split(df_ok, y, groups))
df_dev  = df_ok.iloc[train_dev_idx].reset_index(drop=True)
df_test = df_ok.iloc[test_idx].reset_index(drop=True)

#Save TEST manifest (no blur filtering)
test_csv = SPLITS_ROOT / "test.csv"
df_test[["cache_path","filepath","class","class_idx","patient_id","vol_320"]].to_csv(test_csv, index=False)
print(f"[OK] Saved held-out test set: {test_csv}  (n={len(df_test)})")

#2. 5-fold StratifiedGroupKFold on DEV (stratify by class, group by patient)
sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=SEED)
folds = list(sgkf.split(df_dev, df_dev["class_idx"], df_dev["patient_id"]))

#Meta info
meta = {
    "img_size": IMG_SIZE,
    "use_median": bool(USE_MEDIAN),
    "vol_percentile": float(VOL_PERCENTILE),
    "n_dev": int(len(df_dev)),
    "n_test": int(len(df_test)),
}
with open(SPLITS_ROOT / "meta.json", "w") as f:
    json.dump(meta, f, indent=2)
print(f"[OK] Wrote meta.json")

"""4.4. For each fold: choose τ on TRAIN, filter train by blur (keep val intact), save CSVs"""

def choose_tau_from_train(df_train: pd.DataFrame, percentile: float) -> float:
    scores = df_train["vol_320"].dropna().values
    if len(scores) == 0:
        #Fallback if no VoL available (should not happen with cache step)
        return 0.0
    return float(np.percentile(scores, percentile))

def save_fold_csvs(k: int, train_df: pd.DataFrame, val_df: pd.DataFrame, tau: float):
    fold_dir = SPLITS_ROOT / f"fold_{k}"
    fold_dir.mkdir(parents=True, exist_ok=True)

    #Filter TRAIN by blur threshold (train only)
    keep_mask = (train_df["vol_320"].notna()) & (train_df["vol_320"] >= tau)
    kept  = train_df[keep_mask].copy()
    dropd = train_df[~keep_mask].copy()

    kept_csv   = fold_dir / "train.csv"
    drop_csv   = fold_dir / "train_dropped_blur.csv"
    val_csv    = fold_dir / "val.csv"
    thresh_json= fold_dir / "qc_threshold.json"

    kept[["cache_path","filepath","class","class_idx","patient_id","vol_320"]].to_csv(kept_csv, index=False)
    dropd[["cache_path","filepath","class","class_idx","patient_id","vol_320"]].to_csv(drop_csv, index=False)
    val_df[["cache_path","filepath","class","class_idx","patient_id","vol_320"]].to_csv(val_csv, index=False)

    with open(thresh_json, "w") as f:
        json.dump({"tau_vol_p": VOL_PERCENTILE, "tau_value": tau,
                   "n_train_raw": int(len(train_df)),
                   "n_train_kept": int(len(kept)),
                   "n_train_dropped": int(len(dropd)),
                   "n_val": int(len(val_df))}, f, indent=2)

    print(f"[FOLD {k}] τ={tau:.2f} | train kept={len(kept)} dropped={len(dropd)} | val={len(val_df)}")
    return kept_csv, val_csv, drop_csv, thresh_json

#Iterate folds
for k, (tr_idx, va_idx) in enumerate(folds, start=1):
    df_tr = df_dev.iloc[tr_idx].reset_index(drop=True)
    df_va = df_dev.iloc[va_idx].reset_index(drop=True)

    #Choose per-fold tau from TRAIN only
    tau_k = choose_tau_from_train(df_tr, VOL_PERCENTILE)

    #Save per-fold CSVs + QC logs
    save_fold_csvs(k, df_tr, df_va, tau_k)

print("[OK] All folds saved under:", SPLITS_ROOT)

"""4.5. Loader Stub to Avoid re-running all blocks of code each time you disconnect from the Environment. So, RUN THIS IF YOU DISCONNECT."""

import pandas as pd
import cv2
import torch
from torch.utils.data import Dataset, DataLoader
import albumentations as A
from albumentations.pytorch import ToTensorV2

#Minimal dataset that reads cached 320×320 RGB and applies only transforms (no heavy preprocessing)
class CachedGBDDataset(Dataset):
    def __init__(self, csv_path, transform):
        self.df = pd.read_csv(csv_path)
        self.transform = transform
        self.class_to_idx = {c:i for i,c in enumerate(sorted(self.df["class"].unique()))}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, i):
        row = self.df.iloc[i]
        #read cached RGB directly
        arr = np.fromfile(row.cache_path, dtype=np.uint8)
        rgb = cv2.imdecode(arr, cv2.IMREAD_COLOR)  #BGR
        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)
        aug = self.transform(image=rgb)
        x = aug["image"]
        y = int(row.class_idx)
        return x, y, row.cache_path

#Example: load fold 1
train_csv = SPLITS_ROOT / "fold_1" / "train.csv"
val_csv   = SPLITS_ROOT / "fold_1" / "val.csv"

#Same transforms as before (z-score + light augs for train)
class PerImageZScore(A.ImageOnlyTransform):
    def __init__(self, p=1.0, eps=1e-6):
        super().__init__(always_apply=True, p=p); self.eps = eps
    def apply(self, img, **params):
        img = img.astype(np.float32); mu, sd = img.mean(), img.std()
        return (img - mu) / max(sd, self.eps)

train_tf = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.0, scale_limit=0.10, rotate_limit=10,
                       border_mode=cv2.BORDER_CONSTANT, p=0.8),
    A.RandomBrightnessContrast(0.15, 0.15, p=0.8),
    PerImageZScore(p=1.0),
    ToTensorV2(),
])
eval_tf = A.Compose([PerImageZScore(p=1.0), ToTensorV2()])

train_ds = CachedGBDDataset(train_csv, transform=train_tf)
val_ds   = CachedGBDDataset(val_csv,   transform=eval_tf)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)

xb, yb, fp = next(iter(train_loader))
print("Batch:", xb.shape, yb.shape)

"""# 5. Model Training

5.1. Install & imports
"""

#T1 — Installs & imports (compatible stack; no NumPy change)
#We only ensure sklearn>=1.6 to avoid the umap-learn complaint.
#If these are already satisfied, pip does nothing.

!pip -q install --upgrade "scikit-learn>=1.6.0" timm==0.9.12 albumentations==1.4.4 opencv-python==4.9.0.80

import numpy as np, cv2, sklearn, albumentations, timm, torch
import torch.nn as nn
import torch.nn.functional as F
from dataclasses import dataclass, asdict
from typing import List
from sklearn.metrics import f1_score
import gc

print("NumPy:", np.__version__)                 #keep this at 1.26.x
print("OpenCV:", cv2.__version__)               #4.9.0.80
print("scikit-learn:", sklearn.__version__)     #>= 1.6
print("Albumentations:", albumentations.__version__)
print("timm:", timm.__version__)
print("Torch:", torch.__version__)

"""5.2. Config."""

#T2 — Global config (A100-optimised) (Original Methodology)
from pathlib import Path
import random, numpy as np, torch

#SETTING PATHS
PROJ_ROOT   = Path("/content/drive/MyDrive/AI/Project_Summer_Module") #CHANGE if running on your own machine. This is the root folder for the project.
CACHE_ROOT  = PROJ_ROOT / "cache_320_rgb_v1"      #Drive cache (persistent)
SPLITS_ROOT = PROJ_ROOT / "splits_5fold_v1"       #Folder for the splits
CKPT_ROOT   = PROJ_ROOT / "checkpoints"           #Folder to save the model checkpoints.
RUNS_ROOT   = PROJ_ROOT / "runs"                  #Folder to save results from the runs.
for p in [CKPT_ROOT, RUNS_ROOT]:
    p.mkdir(parents=True, exist_ok=True)

#Optional local staging (MUCH faster than reading from Drive)
LOCAL_CACHE_ROOT = Path("/content/cache_320_rgb_v1")  #ephemeral; we rsync here below

#DATA AND LOADERS
IMG_SIZE = 320

#A100-friendly defaults (you can nudge these up/down)
BATCH_SIZE_MICRO   = 32   #try 64 if it fits; drop to 40 if OOM
ACCUM_STEPS        = 1    #effective batch = micro * accum
NUM_WORKERS        = 4    #try 6–8 if Colab VM has CPU headroom
PREFETCH_FACTOR    = 4
PERSISTENT_WORKERS = True
PIN_MEMORY         = True

#TRAINING SCHEDULE
EPOCHS   = 50
PATIENCE = 8
MIXED_PRECISION = True
SEED = 42

#FOLDS AND MODELS
FOLDS_TO_TRAIN = [1, 2, 3, 4, 5]
MODELS_TO_TRAIN = [
    ("ghostnet_100",     "GhostNet-1.0"),
    ("tiny_vit_11m_224", "TinyViT-11M"),
    ("resnet50",         "ResNet-50"),
]

#Repro and device
random.seed(SEED); np.random.seed(SEED)
torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = False
torch.backends.cudnn.benchmark = True       #let cuDNN pick fastest kernels
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#Optional: enable extra speed features in trainer
SPEED_MODE     = True     #channels_last for CNNs, etc.
COMPILE_MODEL  = False    #set True to try torch.compile (first epoch slower, then faster)

print(f"[Device] {device} | micro-batch={BATCH_SIZE_MICRO} x accum={ACCUM_STEPS} | "
      f"workers={NUM_WORKERS} prefetch={PREFETCH_FACTOR} persistent={PERSISTENT_WORKERS}")

"""Global Config FINAL (grayscale + sampler)"""

#T2: Global config (grayscale + sampler, MixUp OFF)
from pathlib import Path

#Image size and channel mode
IMG_SIZE = 224
USE_SINGLE_CHANNEL = True  #train 1-channel throughout

#Conditional per-image repair thresholds (uint8 grayscale domain)
LOW_CONTRAST_STD = 25.0      #if image std < 25 then apply CLAHE
NOISE_THRESH_HP  = 22.0      #if Laplacian mean|.| > 22 then denoise
CLAHE_CLIP       = 2.0
CLAHE_TILE       = 8

#Augmentations
GAUSS_BLUR_P = 0.30          #GaussianBlur probability in training

#Imbalance handling
USE_WEIGHTED_SAMPLER = True  #sampler for TRAIN loader only

#Training runtime knobs (keep your previous values if you prefer)
EPOCHS          = 50
PATIENCE        = 7
BATCH_SIZE_MICRO= 64         #safe on A100; raise if you want faster epochs
ACCUM_STEPS     = 1
NUM_WORKERS     = 6
PREFETCH_FACTOR = 4
PERSISTENT_WORKERS = True
PIN_MEMORY      = True
SPEED_MODE      = True        #channels_last for CNNs
MIXED_PRECISION = True        #AMP

#FOLDS AND MODELS
FOLDS_TO_TRAIN = [1, 2, 3, 4, 5]
MODELS_TO_TRAIN = [
    ("ghostnet_100",     "GhostNet-1.0"),
    ("tiny_vit_11m_224", "TinyViT-11M"),
    ("resnet50",         "ResNet-50"),
]

#MixUp disabled (we’ll use CE + label smoothing)
USE_MIXUP     = False
LABEL_SMOOTH  = 0.05

#Output dirs (leave as-is if already set elsewhere)
CKPT_ROOT = Path("/content/drive/MyDrive/AI/Project_Summer_Module/checkpoints")
RUNS_ROOT = Path("/content/drive/MyDrive/AI/Project_Summer_Module/runs")
CKPT_ROOT.mkdir(parents=True, exist_ok=True)
RUNS_ROOT.mkdir(parents=True, exist_ok=True)

#Device (guard)
import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

"""5.3. Datasets & transforms."""

#T3: Datasets and transforms (ImageNet normalisation + local mapping)
import albumentations as A
from albumentations.pytorch import ToTensorV2
import pandas as pd, numpy as np, cv2
from torch.utils.data import Dataset, DataLoader

IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD  = (0.229, 0.224, 0.225)

train_tf = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.0, scale_limit=0.10, rotate_limit=10,
                       border_mode=cv2.BORDER_CONSTANT, p=0.8),
    A.RandomBrightnessContrast(0.15, 0.15, p=0.8),
    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
    ToTensorV2(),
])

eval_tf = A.Compose([
    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
    ToTensorV2(),
])

#helpers for path remap (Drive to local SSD)
def _maybe_local_path(path_str: str) -> str:
    from pathlib import Path
    try:
        drive_prefix = str(CACHE_ROOT.resolve())
        if 'LOCAL_CACHE_ROOT' in globals() and LOCAL_CACHE_ROOT.exists():
            local_prefix = str(LOCAL_CACHE_ROOT.resolve())
            if path_str.startswith(drive_prefix):
                candidate = path_str.replace(drive_prefix, local_prefix, 1)
                if Path(candidate).exists():
                    return candidate
    except Exception:
        pass
    return path_str

class CachedGBDDataset(Dataset):
    def __init__(self, csv_path, transform):
        self.df = pd.read_csv(csv_path)
        assert {"cache_path", "class_idx"}.issubset(self.df.columns)
        self.transform = transform

    def __len__(self): return len(self.df)

    def __getitem__(self, i):
        row = self.df.iloc[i]
        path_to_read = _maybe_local_path(str(row.cache_path))
        arr = np.fromfile(path_to_read, dtype=np.uint8)
        bgr = cv2.imdecode(arr, cv2.IMREAD_COLOR)
        if bgr is None:
            raise RuntimeError(f"Failed to read: {path_to_read}")
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
        x = self.transform(image=rgb)["image"]
        y = int(row.class_idx)
        return x, y, path_to_read

"""Datasets & transforms - Version 2 (stronger, safe aug + ImageNet norm)"""

#T3: Datasets & transforms (stronger, safe aug + ImageNet normalisation)
import albumentations as A
from albumentations.pytorch import ToTensorV2
import pandas as pd, numpy as np, cv2
from torch.utils.data import Dataset, DataLoader
from pathlib import Path

IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD  = (0.229, 0.224, 0.225)

#Slightly stronger but anatomy-safe augmentation
train_tf = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.0, scale_limit=0.12, rotate_limit=12,
                       border_mode=cv2.BORDER_CONSTANT, p=0.9),
    A.RandomBrightnessContrast(0.2, 0.2, p=0.9),
    A.CoarseDropout(max_holes=1, max_height=IMG_SIZE//10, max_width=IMG_SIZE//10,
                    fill_value=0, p=0.30),
    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
    ToTensorV2(),
])

eval_tf = A.Compose([
    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
    ToTensorV2(),
])

#Optional Drive to local SSD mapping if you staged the cache
def _maybe_local_path(path_str: str) -> str:
    try:
        if 'LOCAL_CACHE_ROOT' in globals() and Path(LOCAL_CACHE_ROOT).exists():
            drive_prefix = str(CACHE_ROOT.resolve())
            local_prefix = str(LOCAL_CACHE_ROOT.resolve())
            if path_str.startswith(drive_prefix):
                candidate = path_str.replace(drive_prefix, local_prefix, 1)
                if Path(candidate).exists():
                    return candidate
    except Exception:
        pass
    return path_str

class CachedGBDDataset(Dataset):
    """Reads cached RGB PNGs (IMG_SIZE×IMG_SIZE) listed in split CSVs."""
    def __init__(self, csv_path, transform):
        self.df = pd.read_csv(csv_path)
        assert {"cache_path","class_idx"}.issubset(self.df.columns)
        self.transform = transform

    def __len__(self): return len(self.df)

    def __getitem__(self, i):
        row = self.df.iloc[i]
        p = _maybe_local_path(str(row.cache_path))
        arr = np.fromfile(p, dtype=np.uint8)
        bgr = cv2.imdecode(arr, cv2.IMREAD_COLOR)
        if bgr is None:
            raise RuntimeError(f"Failed to read: {p}")
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
        x = self.transform(image=rgb)["image"]
        y = int(row.class_idx)
        return x, y, p

"""Dataset & transforms FINAL"""

#T3: Dataset (1-channel) + conditional repairs + blur aug
import cv2, numpy as np, pandas as pd, torch
from torch.utils.data import Dataset
import albumentations as A
from albumentations.pytorch import ToTensorV2

#Albumentations (expects HWC; we pass C=1 tensors)
train_tf = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_AREA),
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=10, border_mode=cv2.BORDER_CONSTANT, value=0, p=0.5),
    A.GaussianBlur(blur_limit=(3, 3), p=GAUSS_BLUR_P),  #Blur
    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),
    A.Normalize(mean=(0.5,), std=(0.5,)),               #1-channel norm
    ToTensorV2(),
])

eval_tf = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_AREA),
    A.Normalize(mean=(0.5,), std=(0.5,)),               #1-channel norm
    ToTensorV2(),
])

def _maybe_repair_uint8_gray(img_u8: np.ndarray) -> np.ndarray:
    """CLAHE if contrast is low; NLM denoise if high-pass energy is high."""
    std = float(img_u8.std())
    hp  = cv2.Laplacian(img_u8, cv2.CV_16S)
    hp_mean_abs = float(np.mean(np.abs(hp)))

    if std < LOW_CONTRAST_STD:
        clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP, tileGridSize=(CLAHE_TILE, CLAHE_TILE))
        img_u8 = clahe.apply(img_u8)

    if hp_mean_abs > NOISE_THRESH_HP:
        img_u8 = cv2.fastNlMeansDenoising(img_u8, h=6, templateWindowSize=7, searchWindowSize=21)

    return img_u8

class CachedGBDDataset(Dataset):
    """Grayscale loader with conditional repairs; returns (tensor[1,H,W], label, path)."""
    def __init__(self, csv_path, transform):
        self.df = pd.read_csv(csv_path)
        self.transform = transform

    def __len__(self): return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        fp  = row["filepath"]
        y   = int(row["class_idx"])

        img = cv2.imread(fp, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise FileNotFoundError(fp)

        img = _maybe_repair_uint8_gray(img)   #conditional fixes

        img = img[..., None]  #(H,W,1) for Albumentations
        if self.transform is not None:
            img = self.transform(image=img)["image"]  #torch.float32 [1,H,W]

        return img, y, fp

"""5.4. Batch-Balanced Focal Loss (Original Methodology). DEPRICATED. DO NOT RUN"""

class BatchBalancedFocalLoss(nn.Module):
    def __init__(self, gamma: float = 2.0, eps: float = 1e-6):
        super().__init__()
        self.gamma = gamma; self.eps = eps

    @torch.no_grad()
    def _alpha_from_targets(self, targets: torch.Tensor, num_classes: int) -> torch.Tensor:
        counts = torch.bincount(targets, minlength=num_classes).float()
        alpha = 1.0 / (counts + self.eps)
        alpha = alpha * (num_classes / alpha.sum().clamp_min(self.eps))  #normalise
        return alpha

    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        num_classes = logits.size(1)
        log_probs = F.log_softmax(logits, dim=1)
        probs = log_probs.exp()
        p_t = probs[torch.arange(logits.size(0), device=logits.device), targets]
        log_p_t = log_probs[torch.arange(logits.size(0), device=logits.device), targets]
        alpha = self._alpha_from_targets(targets, num_classes)  #(C,)
        alpha_t = alpha[targets]                                 #(N,)
        focal = (1.0 - p_t).pow(self.gamma)
        loss = - alpha_t * focal * log_p_t
        return loss.mean()

"""5.5. Warmup+Cosine scheduler, eval, plotting. DEPRICATED DO NOT RUN"""

@dataclass
class TrainHistory:
    epoch: List[int]
    train_loss: List[float]
    val_loss: List[float]
    train_f1: List[float]
    val_f1: List[float]
    lrs: List[float]

def make_warmup_cosine(optimizer, warmup_epochs: int, max_epochs: int, base_lr: float, min_lr: float):
    def set_lr(lr):
        for pg in optimizer.param_groups: pg["lr"] = lr
    def step(epoch_idx: int):
        if epoch_idx < warmup_epochs:
            lr = base_lr * float(epoch_idx + 1) / float(max(1, warmup_epochs))
        else:
            t = (epoch_idx - warmup_epochs) / max(1, (max_epochs - warmup_epochs))
            lr = min_lr + 0.5 * (base_lr - min_lr) * (1 + math.cos(math.pi * t))
        set_lr(lr); return lr
    return step

@torch.no_grad()
def evaluate(model, loader, device):
    model.eval()
    loss_fn = BatchBalancedFocalLoss(gamma=2.0)
    all_targets, all_preds = [], []
    running_loss, n = 0.0, 0
    for xb, yb, _ in tqdm(loader, desc="Valid", leave=False):
        xb, yb = xb.to(device), yb.to(device)
        logits = model(xb)
        loss = loss_fn(logits, yb)
        running_loss += loss.item() * xb.size(0); n += xb.size(0)
        preds = torch.argmax(logits, dim=1)
        all_targets.append(yb.detach().cpu().numpy())
        all_preds.append(preds.detach().cpu().numpy())
    avg_loss = running_loss / max(1, n)
    y_true = np.concatenate(all_targets); y_pred = np.concatenate(all_preds)
    macro_f1 = f1_score(y_true, y_pred, average="macro")
    return avg_loss, macro_f1

def plot_curves(hist: TrainHistory, out_dir: Path, run_name: str):
    out_dir.mkdir(parents=True, exist_ok=True)
    #Loss
    plt.figure(figsize=(7,4))
    plt.plot(hist.epoch, hist.train_loss, label="Train loss")
    plt.plot(hist.epoch, hist.val_loss,   label="Val loss")
    plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.title(f"Loss — {run_name}")
    plt.legend(); plt.tight_layout()
    plt.savefig(out_dir / f"{run_name}_loss.png", dpi=220); plt.show()
    #Macro-F1
    plt.figure(figsize=(7,4))
    plt.plot(hist.epoch, hist.train_f1, label="Train macro-F1")
    plt.plot(hist.epoch, hist.val_f1,   label="Val macro-F1")
    plt.xlabel("Epoch"); plt.ylabel("Macro-F1"); plt.title(f"Macro-F1 — {run_name}")
    plt.legend(); plt.tight_layout()
    plt.savefig(out_dir / f"{run_name}_macroF1.png", dpi=220); plt.show()
    #CSV log
    df = pd.DataFrame({
        "epoch": hist.epoch,
        "train_loss": hist.train_loss,
        "val_loss": hist.val_loss,
        "train_macro_f1": hist.train_f1,
        "val_macro_f1": hist.val_f1,
        "lr": hist.lrs,
    })
    df.to_csv(out_dir / f"{run_name}_history.csv", index=False)
    print(f"[OK] Saved curves & history to: {out_dir}")

"""5.5. Plotting Helper."""

#5.5: plotting helper only
import matplotlib.pyplot as plt
from pathlib import Path

def plot_curves(hist, out_dir: Path, run_tag: str):
    """
    Save loss and macro-F1 curves for a run.
    hist: dataclass with lists: epoch, train_loss, val_loss, train_f1, val_f1
    out_dir: directory for run artifacts
    run_tag: e.g., 'GhostNet-1.0_fold1'
    """
    out_dir.mkdir(parents=True, exist_ok=True)

    #Loss
    plt.figure(figsize=(6.5, 4.0))
    plt.plot(hist.epoch, hist.train_loss, label="Train loss")
    plt.plot(hist.epoch, hist.val_loss,   label="Val loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title(f"Loss — {run_tag}")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.savefig(out_dir / f"{run_tag}_loss.png", dpi=150)
    plt.close()

    #Macro-F1
    plt.figure(figsize=(6.5, 4.0))
    plt.plot(hist.epoch, hist.train_f1, label="Train macro-F1")
    plt.plot(hist.epoch, hist.val_f1,   label="Val macro-F1")
    plt.xlabel("Epoch")
    plt.ylabel("Macro-F1")
    plt.title(f"Macro-F1 — {run_tag}")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.savefig(out_dir / f"{run_tag}_macroF1.png", dpi=150)
    plt.close()

"""5.6. Model factory."""

#T6: Model factory and utilities for linear-probe + discriminative LRs
import timm
import torch.nn as nn

def build_model(timm_name: str, num_classes: int) -> nn.Module:
    """
    Create a timm backbone with pretrained weights and a modest dropout on the head
    to improve generalisation on small medical datasets.
    """
    model = timm.create_model(
        timm_name,
        pretrained=True,
        num_classes=num_classes,
        drop_rate=0.20  #gentle regularisation on classifier
    )
    return model

def set_trainable(module: nn.Module, flag: bool):
    for p in module.parameters():
        p.requires_grad = flag

def get_head_module(model: nn.Module) -> nn.Module:
    """
    Try common head attributes across timm models.
    """
    for attr in ["classifier", "fc", "head"]:
        if hasattr(model, attr):
            mod = getattr(model, attr)
            if isinstance(mod, nn.Module):
                return mod
    #fallback to timm's getter
    head = model.get_classifier()
    if isinstance(head, nn.Module):
        return head
    raise RuntimeError("Could not locate classifier head module.")

def split_params_head_backbone(model: nn.Module):
    """
    Returns two lists of parameters: (head_params, backbone_params).
    """
    head = get_head_module(model)
    head_ids = {id(p) for p in head.parameters()}
    head_params, backbone_params = [], []
    for p in model.parameters():
        (head_params if id(p) in head_ids else backbone_params).append(p)
    return head, head_params, backbone_params

"""Model factory Version 2 (dropout + drop-path where available)"""

#T6: Model factory & utilities (dropout + drop-path if supported)
import timm, inspect
import torch.nn as nn

def build_model(timm_name: str, num_classes: int) -> nn.Module:
    """
    Create a timm model with pretrained weights.
    - drop_rate: modest head dropout to improve generalisation
    - drop_path_rate: mild stochastic depth where the backbone supports it
    """
    kwargs = dict(pretrained=True, num_classes=num_classes, drop_rate=0.20)
    try:
        #Some backbones support stochastic depth
        model = timm.create_model(timm_name, **kwargs, drop_path_rate=0.10)
    except TypeError:
        model = timm.create_model(timm_name, **kwargs)
    return model

def set_trainable(module: nn.Module, flag: bool):
    for p in module.parameters():
        p.requires_grad = flag

def get_head_module(model: nn.Module) -> nn.Module:
    for attr in ["classifier", "fc", "head"]:
        if hasattr(model, attr) and isinstance(getattr(model, attr), nn.Module):
            return getattr(model, attr)
    head = model.get_classifier()
    if isinstance(head, nn.Module):
        return head
    raise RuntimeError("Could not locate classifier head module.")

def split_params_head_backbone(model: nn.Module):
    head = get_head_module(model)
    head_ids = {id(p) for p in head.parameters()}
    head_params, backbone_params = [], []
    for p in model.parameters():
        (head_params if id(p) in head_ids else backbone_params).append(p)
    return head, head_params, backbone_params

"""Model factory (force in_chans=1 + mild dropout / drop-path) FINAL"""

#T6: Model factory (in_chans=1 + mild dropout/drop-path)
import timm, torch
import torch.nn as nn

def _replace_first_conv_to_1ch(model: nn.Module):
    """Fallback: if a model doesn't accept in_chans=1, patch first Conv2d."""
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d) and getattr(m, "in_channels", None) == 3:
            new = nn.Conv2d(
                in_channels=1, out_channels=m.out_channels, kernel_size=m.kernel_size,
                stride=m.stride, padding=m.padding, dilation=m.dilation,
                groups=1, bias=(m.bias is not None), padding_mode=m.padding_mode
            )
            with torch.no_grad():
                new.weight[:] = m.weight.data.mean(dim=1, keepdim=True)
                if m.bias is not None:
                    new.bias[:] = m.bias.data
            parent = model
            parts = name.split(".")
            for p in parts[:-1]:
                parent = getattr(parent, p)
            setattr(parent, parts[-1], new)
            return model
    return model

def build_model(timm_name: str, num_classes: int):
    kwargs = dict(pretrained=True, in_chans=1, num_classes=num_classes,
                  drop_rate=0.2, drop_path_rate=0.1)  #ignored if unsupported
    try:
        model = timm.create_model(timm_name, **kwargs)
    except TypeError:
        model = timm.create_model(timm_name, pretrained=True, num_classes=num_classes)
        model = _replace_first_conv_to_1ch(model)
    return model

#Split head vs backbone (works across timm CNNs/ViTs)
def split_params_head_backbone(model: nn.Module):
    head = None
    #common names
    for attr in ["classifier", "head", "fc"]:
        if hasattr(model, attr) and isinstance(getattr(model, attr), nn.Module):
            head = getattr(model, attr)
            break
    if head is None and hasattr(model, "get_classifier"):
        try:
            head = model.get_classifier()
        except Exception:
            head = None
    if head is None:
        #fallback: last Linear in module tree
        last_linear = None
        for m in model.modules():
            if isinstance(m, nn.Linear):
                last_linear = m
        head = last_linear if last_linear is not None else model

    head_params = list(head.parameters()) if head is not None else []
    head_param_ids = {id(p) for p in head_params}
    backbone_params = [p for p in model.parameters() if id(p) not in head_param_ids]
    return head, head_params, backbone_params

"""5.7. Trainer."""

#T7: Trainer (A100-speed tweaks + linear-probe & discr. LRs kept)
import math, time, gc
import torch
import torch.nn as nn
import torch.nn.functional as F
from dataclasses import dataclass, asdict
from typing import List
from tqdm.auto import tqdm
import numpy as np
from sklearn.metrics import f1_score
from torch.utils.data import DataLoader

#linter guards (pull from T2 if present)
BATCH_SIZE_MICRO   = globals().get("BATCH_SIZE_MICRO", 48)
ACCUM_STEPS        = globals().get("ACCUM_STEPS", 1)
NUM_WORKERS        = globals().get("NUM_WORKERS", 4)
PREFETCH_FACTOR    = globals().get("PREFETCH_FACTOR", 4)
PERSISTENT_WORKERS = globals().get("PERSISTENT_WORKERS", True)
PIN_MEMORY         = globals().get("PIN_MEMORY", True)
SPEED_MODE         = globals().get("SPEED_MODE", True)
COMPILE_MODEL      = globals().get("COMPILE_MODEL", False)

def make_warmup_cosine_dual(optimizer, warmup_epochs, max_epochs,
                            base_head, base_backbone, min_head, min_backbone):
    def set_lrs(lr_h, lr_b):
        optimizer.param_groups[0]["lr"] = lr_h
        optimizer.param_groups[1]["lr"] = lr_b
    def step(epoch_idx: int):
        if epoch_idx < warmup_epochs:
            s = float(epoch_idx + 1) / max(1, warmup_epochs)
            lr_h, lr_b = base_head*s, base_backbone*s
        else:
            t = (epoch_idx - warmup_epochs) / max(1, (max_epochs - warmup_epochs))
            cos = 0.5 * (1 + math.cos(math.pi * t))
            lr_h = min_head     + (base_head     - min_head)     * cos
            lr_b = min_backbone + (base_backbone - min_backbone) * cos
        set_lrs(lr_h, lr_b); return lr_h, lr_b
    return step

def train_one_run(
    timm_name: str,
    pretty_name: str,
    fold_id: int,
    train_csv,
    val_csv,
    weight_decay_head: float = 0.01,
    weight_decay_backbone: float = 0.01,
):
    run_tag = f"{pretty_name}_fold{fold_id}"
    out_ckpt_dir = CKPT_ROOT / pretty_name.replace(" ", "_")
    out_run_dir  = RUNS_ROOT / pretty_name.replace(" ", "_")
    out_ckpt_dir.mkdir(parents=True, exist_ok=True)
    out_run_dir.mkdir(parents=True, exist_ok=True)

    #Data
    train_ds = CachedGBDDataset(train_csv, transform=train_tf)
    val_ds   = CachedGBDDataset(val_csv,   transform=eval_tf)
    num_classes = int(max(train_ds.df["class_idx"].max(), val_ds.df["class_idx"].max()) + 1)
    print(f"[{run_tag}] C={num_classes} | train={len(train_ds)} | val={len(val_ds)}")

    dl_train = dict(batch_size=BATCH_SIZE_MICRO, shuffle=True,
                    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)
    dl_val   = dict(batch_size=BATCH_SIZE_MICRO, shuffle=False,
                    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)
    if NUM_WORKERS > 0:
        dl_train.update(prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT_WORKERS)
        dl_val.update(prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT_WORKERS)
    train_loader = DataLoader(train_ds, **dl_train)
    val_loader   = DataLoader(val_ds,   **dl_val)

    #Model
    model = build_model(timm_name, num_classes=num_classes).to(device)
    is_vit = "vit" in timm_name.lower()

    #SPEED: channels_last helps CNNs (leave ViTs default)
    if SPEED_MODE and not is_vit:
        model = model.to(memory_format=torch.channels_last)

    #Optional compile (PyTorch 2.8+). First epoch slower, then faster.
    if SPEED_MODE and COMPILE_MODEL:
        try:
            model = torch.compile(model, mode="max-autotune")
            print("[compile] torch.compile enabled")
        except Exception as e:
            print("[compile] skipped:", e)

    #Head/backbone split
    head_module, head_params, backbone_params = split_params_head_backbone(model)

    #Phase A: linear probe (freeze backbone)
    FREEZE_EPOCHS = 5 if is_vit else 3
    for p in backbone_params: p.requires_grad = False
    for p in head_params:     p.requires_grad = True

    #Discriminative LRs (head higher)
    BASE_LR_HEAD     = 3e-4
    BASE_LR_BACKBONE = 5e-5 if is_vit else 1e-4
    MIN_LR_HEAD      = 1e-6
    MIN_LR_BACKBONE  = 1e-6

    optimizer = torch.optim.AdamW([
        {"params": head_params,     "lr": BASE_LR_HEAD,     "weight_decay": weight_decay_head},
        {"params": backbone_params, "lr": BASE_LR_BACKBONE, "weight_decay": weight_decay_backbone},
    ])
    sched_dual = make_warmup_cosine_dual(
        optimizer, warmup_epochs=(5 if is_vit else 3), max_epochs=EPOCHS,
        base_head=BASE_LR_HEAD, base_backbone=BASE_LR_BACKBONE,
        min_head=MIN_LR_HEAD,   min_backbone=MIN_LR_BACKBONE
    )

    loss_fn = BatchBalancedFocalLoss(gamma=2.0)
    scaler  = torch.amp.GradScaler('cuda', enabled=MIXED_PRECISION)

    #History / ES
    hist = TrainHistory(epoch=[], train_loss=[], val_loss=[], train_f1=[], val_f1=[], lrs=[])
    best_f1, best_epoch, no_improve = -1.0, -1, 0

    for epoch in range(EPOCHS):
        #Phase B: unfreeze backbone after probe
        if epoch == FREEZE_EPOCHS:
            for p in backbone_params: p.requires_grad = True

        lr_h, lr_b = sched_dual(epoch)

        #Train
        model.train()
        optimizer.zero_grad(set_to_none=True)
        run_loss, n = 0.0, 0
        y_true_tr, y_pred_tr = [], []

        pbar = tqdm(train_loader, desc=f"Train {run_tag} — epoch {epoch+1}/{EPOCHS}", leave=False)
        for step, (xb, yb, _) in enumerate(pbar, start=1):
            xb = xb.to(device, non_blocking=True)
            if SPEED_MODE and not is_vit:
                xb = xb.to(memory_format=torch.channels_last)
            yb = yb.to(device, non_blocking=True)

            with torch.amp.autocast('cuda', enabled=MIXED_PRECISION):
                logits = model(xb)
                loss = loss_fn(logits, yb) / ACCUM_STEPS

            scaler.scale(loss).backward()

            if step % ACCUM_STEPS == 0 or step == len(train_loader):
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                scaler.step(optimizer); scaler.update()
                optimizer.zero_grad(set_to_none=True)

            run_loss += loss.item() * xb.size(0) * ACCUM_STEPS
            n += xb.size(0)
            preds = torch.argmax(logits.detach(), dim=1)
            y_true_tr.append(yb.detach().cpu().numpy())
            y_pred_tr.append(preds.cpu().numpy())
            pbar.set_postfix_str(f"loss={(loss.item()*ACCUM_STEPS):.4f} lr_h={lr_h:.1e} lr_b={lr_b:.1e}")

        train_loss = run_loss / max(1, n)
        train_f1 = f1_score(np.concatenate(y_true_tr), np.concatenate(y_pred_tr), average="macro")

        #Validate
        val_loss, val_f1 = evaluate(model, val_loader, device)

        #Log
        hist.epoch.append(epoch+1)
        hist.train_loss.append(train_loss)
        hist.val_loss.append(val_loss)
        hist.train_f1.append(train_f1)
        hist.val_f1.append(val_f1)
        hist.lrs.append(lr_h)

        tqdm.write(f"[{run_tag}] Epoch {epoch+1:02d} | "
                   f"train_loss={train_loss:.4f} val_loss={val_loss:.4f} | "
                   f"train_f1={train_f1:.4f} val_f1={val_f1:.4f}")

        improved = val_f1 > best_f1 + 1e-6
        if improved:
            best_f1, best_epoch, no_improve = val_f1, epoch+1, 0
            ckpt_path = out_ckpt_dir / f"{pretty_name.replace(' ','_')}_fold{fold_id}_best.pt"
            torch.save({
                "model_name": timm_name,
                "pretty_name": pretty_name,
                "state_dict": model.state_dict(),
                "optimizer": optimizer.state_dict(),
                "epoch": best_epoch,
                "num_classes": num_classes,
                "img_size": IMG_SIZE,
                "history": asdict(hist),
            }, ckpt_path)
            tqdm.write(f"[{run_tag}] Saved best checkpoint: {ckpt_path}")
        else:
            no_improve += 1

        if no_improve >= PATIENCE:
            tqdm.write(f"[{run_tag}] Early stopping (no val F1 improvement for {PATIENCE} epochs).")
            break

        torch.cuda.empty_cache(); gc.collect()

    plot_curves(hist, out_run_dir, run_tag)
    return best_f1, best_epoch

"""Trainer Version 2 (CE + class weights; keep staged unfreeze & discr. LRs)"""

#T7: Trainer — CE with class weights + linear-probe then unfreeze + discr. LRs
import math, time, gc
import torch
import torch.nn as nn
import torch.nn.functional as F
from dataclasses import dataclass, asdict
from typing import List
from tqdm.auto import tqdm
import numpy as np, pandas as pd
from sklearn.metrics import f1_score
from torch.utils.data import DataLoader

#linter guards (values from T2 will override at runtime)
BATCH_SIZE_MICRO   = globals().get("BATCH_SIZE_MICRO", 48)
ACCUM_STEPS        = globals().get("ACCUM_STEPS", 1)
NUM_WORKERS        = globals().get("NUM_WORKERS", 4)
PREFETCH_FACTOR    = globals().get("PREFETCH_FACTOR", 4)
PERSISTENT_WORKERS = globals().get("PERSISTENT_WORKERS", True)
PIN_MEMORY         = globals().get("PIN_MEMORY", True)
SPEED_MODE         = globals().get("SPEED_MODE", True)

@dataclass
class TrainHistory:
    epoch: List[int]
    train_loss: List[float]
    val_loss: List[float]
    train_f1: List[float]
    val_f1: List[float]
    lrs: List[float]

def class_weights_from_csv(csv_path, num_classes):
    df = pd.read_csv(csv_path)
    counts = df["class_idx"].value_counts().reindex(range(num_classes), fill_value=0).values.astype(np.float32)
    w = counts.sum() / (counts + 1e-6)
    w = w / w.mean()
    return torch.tensor(w, dtype=torch.float32)

def make_warmup_cosine_dual(optimizer, warmup_epochs, max_epochs,
                            base_head, base_backbone, min_head, min_backbone):
    def set_lrs(lh, lb):
        optimizer.param_groups[0]["lr"] = lh
        optimizer.param_groups[1]["lr"] = lb
    def step(ep):
        if ep < warmup_epochs:
            s = float(ep + 1) / max(1, warmup_epochs)
            lr_h, lr_b = base_head*s, base_backbone*s
        else:
            t = (ep - warmup_epochs) / max(1, (max_epochs - warmup_epochs))
            cos = 0.5 * (1 + math.cos(math.pi * t))
            lr_h = min_head     + (base_head     - min_head)     * cos
            lr_b = min_backbone + (base_backbone - min_backbone) * cos
        set_lrs(lr_h, lr_b); return lr_h, lr_b
    return step

@torch.no_grad()
def evaluate_ce(model, loader, device, ce_loss):
    model.eval()
    run_ce, n = 0.0, 0
    y_true_all, y_pred_all = [], []
    for xb, yb, _ in tqdm(loader, desc="Valid", leave=False):
        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)
        logits = model(xb)
        loss_ce = ce_loss(logits, yb)
        b = xb.size(0)
        run_ce += loss_ce.item() * b
        n += b
        preds = torch.argmax(logits, dim=1)
        y_true_all.append(yb.detach().cpu().numpy())
        y_pred_all.append(preds.detach().cpu().numpy())
    avg_ce = run_ce / max(1, n)
    macro_f1 = f1_score(np.concatenate(y_true_all), np.concatenate(y_pred_all), average="macro")
    return avg_ce, macro_f1

def train_one_run(
    timm_name: str,
    pretty_name: str,
    fold_id: int,
    train_csv,
    val_csv,
    weight_decay_head: float = 0.01,
    weight_decay_backbone: float = 0.01,
):
    run_tag = f"{pretty_name}_fold{fold_id}"
    out_ckpt_dir = CKPT_ROOT / pretty_name.replace(" ", "_")
    out_run_dir  = RUNS_ROOT / pretty_name.replace(" ", "_")
    out_ckpt_dir.mkdir(parents=True, exist_ok=True)
    out_run_dir.mkdir(parents=True, exist_ok=True)

    #Data
    train_ds = CachedGBDDataset(train_csv, transform=train_tf)
    val_ds   = CachedGBDDataset(val_csv,   transform=eval_tf)
    num_classes = int(max(train_ds.df["class_idx"].max(), val_ds.df["class_idx"].max()) + 1)
    print(f"[{run_tag}] C={num_classes} | train={len(train_ds)} | val={len(val_ds)}")

    dl_train = dict(batch_size=BATCH_SIZE_MICRO, shuffle=True,
                    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)
    dl_val   = dict(batch_size=BATCH_SIZE_MICRO, shuffle=False,
                    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)
    if NUM_WORKERS > 0:
        dl_train.update(prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT_WORKERS)
        dl_val.update(prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT_WORKERS)
    train_loader = DataLoader(train_ds, **dl_train)
    val_loader   = DataLoader(val_ds,   **dl_val)

    #Model
    model = build_model(timm_name, num_classes=num_classes).to(device)
    is_vit = "vit" in timm_name.lower()
    if SPEED_MODE and not is_vit:
        model = model.to(memory_format=torch.channels_last)

    #Split head/backbone
    head_module, head_params, backbone_params = split_params_head_backbone(model)

    #Phase A: linear probe (freeze backbone)
    FREEZE_EPOCHS = 5 if is_vit else 3
    for p in backbone_params: p.requires_grad = False
    for p in head_params:     p.requires_grad = True

    #Discriminative LRs
    BASE_LR_HEAD     = 3e-4
    BASE_LR_BACKBONE = 5e-5 if is_vit else 1e-4
    MIN_LR_HEAD      = 1e-6
    MIN_LR_BACKBONE  = 1e-6

    optimizer = torch.optim.AdamW([
        {"params": head_params,     "lr": BASE_LR_HEAD,     "weight_decay": weight_decay_head},
        {"params": backbone_params, "lr": BASE_LR_BACKBONE, "weight_decay": weight_decay_backbone},
    ])
    sched_dual = make_warmup_cosine_dual(
        optimizer, warmup_epochs=(5 if is_vit else 3), max_epochs=EPOCHS,
        base_head=BASE_LR_HEAD, base_backbone=BASE_LR_BACKBONE,
        min_head=MIN_LR_HEAD,   min_backbone=MIN_LR_BACKBONE
    )

    #Loss: Cross-Entropy with class weights (steadier than BBFL here)
    weights = class_weights_from_csv(train_csv, num_classes).to(device)
    ce_loss = nn.CrossEntropyLoss(weight=weights)

    scaler  = torch.amp.GradScaler('cuda', enabled=MIXED_PRECISION)

    hist = TrainHistory(epoch=[], train_loss=[], val_loss=[], train_f1=[], val_f1=[], lrs=[])
    best_f1, best_epoch, no_improve = -1.0, -1, 0

    for epoch in range(EPOCHS):
        #Unfreeze backbone after probe
        if epoch == FREEZE_EPOCHS:
            for p in backbone_params: p.requires_grad = True
            tqdm.write(f"[{run_tag}]  Unfroze backbone at epoch {epoch+1}")

        lr_h, lr_b = sched_dual(epoch)

        #Train
        model.train()
        optimizer.zero_grad(set_to_none=True)
        run_loss, n = 0.0, 0
        y_true_tr, y_pred_tr = [], []

        pbar = tqdm(train_loader, desc=f"Train {run_tag} — epoch {epoch+1}/{EPOCHS}", leave=False)
        for step, (xb, yb, _) in enumerate(pbar, start=1):
            xb = xb.to(device, non_blocking=True)
            if SPEED_MODE and not is_vit:
                xb = xb.to(memory_format=torch.channels_last)
            yb = yb.to(device, non_blocking=True)

            with torch.amp.autocast('cuda', enabled=MIXED_PRECISION):
                logits = model(xb)
                loss = ce_loss(logits, yb) / ACCUM_STEPS

            scaler.scale(loss).backward()

            if step % ACCUM_STEPS == 0 or step == len(train_loader):
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                scaler.step(optimizer); scaler.update()
                optimizer.zero_grad(set_to_none=True)

            run_loss += loss.item() * xb.size(0) * ACCUM_STEPS
            n += xb.size(0)
            preds = torch.argmax(logits.detach(), dim=1)
            y_true_tr.append(yb.detach().cpu().numpy())
            y_pred_tr.append(preds.cpu().numpy())
            pbar.set_postfix_str(f"loss={(loss.item()*ACCUM_STEPS):.4f} lr_h={lr_h:.1e} lr_b={lr_b:.1e}")

        train_loss = run_loss / max(1, n)
        train_f1 = f1_score(np.concatenate(y_true_tr), np.concatenate(y_pred_tr), average="macro")

        #Validate (CE loss)
        val_loss, val_f1 = evaluate_ce(model, val_loader, device, ce_loss)

        #Log
        hist.epoch.append(epoch+1)
        hist.train_loss.append(train_loss)
        hist.val_loss.append(val_loss)
        hist.train_f1.append(train_f1)
        hist.val_f1.append(val_f1)
        hist.lrs.append(lr_h)

        tqdm.write(f"[{run_tag}] Epoch {epoch+1:02d} | "
                   f"train_loss={train_loss:.4f} val_loss={val_loss:.4f} | "
                   f"train_f1={train_f1:.4f} val_f1={val_f1:.4f}")

        improved = val_f1 > best_f1 + 1e-6
        if improved:
            best_f1, best_epoch, no_improve = val_f1, epoch+1, 0
            ckpt_path = out_ckpt_dir / f"{pretty_name.replace(' ','_')}_fold{fold_id}_best.pt"
            torch.save({
                "model_name": timm_name,
                "pretty_name": pretty_name,
                "state_dict": model.state_dict(),
                "optimizer": optimizer.state_dict(),
                "epoch": best_epoch,
                "num_classes": num_classes,
                "img_size": IMG_SIZE,
                "history": asdict(hist),
            }, ckpt_path)
            tqdm.write(f"[{run_tag}]  Saved best checkpoint: {ckpt_path}")
        else:
            no_improve += 1

        if no_improve >= PATIENCE:
            tqdm.write(f"[{run_tag}] Early stopping (no val F1 improvement for {PATIENCE} epochs).")
            break

        torch.cuda.empty_cache(); gc.collect()

    #Curves
    plot_curves(hist, out_run_dir, run_tag)
    return best_f1, best_epoch

"""Trainer Version 3 (safer unfreeze, frozen BN, lower backbone LR, MixUp)"""

#T7 — Trainer (TOP-ONLY UNFREEZE)

import math, gc, torch, numpy as np, pandas as pd
import torch.nn as nn
from dataclasses import dataclass, asdict
from typing import List
from tqdm.auto import tqdm
from sklearn.metrics import f1_score
from torch.utils.data import DataLoader

#Optional MixUp from timm
try:
    from timm.data.mixup import Mixup
    from timm.loss import SoftTargetCrossEntropy
    _HAS_MIXUP = True
except Exception:
    _HAS_MIXUP = False

#linter guards (actual values come from T2)
BATCH_SIZE_MICRO   = globals().get("BATCH_SIZE_MICRO", 48)
ACCUM_STEPS        = globals().get("ACCUM_STEPS", 1)
NUM_WORKERS        = globals().get("NUM_WORKERS", 4)
PREFETCH_FACTOR    = globals().get("PREFETCH_FACTOR", 4)
PERSISTENT_WORKERS = globals().get("PERSISTENT_WORKERS", True)
PIN_MEMORY         = globals().get("PIN_MEMORY", True)
SPEED_MODE         = globals().get("SPEED_MODE", True)
MIXED_PRECISION    = globals().get("MIXED_PRECISION", True)

#regularisation toggles
USE_MIXUP    = True and _HAS_MIXUP      #set False to use CE + label smoothing
MIXUP_PROB   = 0.7
MIXUP_ALPHA  = 0.2
LABEL_SMOOTH = 0.05                      #sonly used when MixUp is off

#L2-SP strength (penalise drift from pretrained backbone) ----
L2SP_LAMBDA  = 5e-4                      #strong tether to ImageNet init

#Unfreeze plan (TOP-ONLY) + layer-wise LR decay
BACKBONE_GROUPS      = 8                 #each group is approx. 12.5% of backbone params
UNFREEZE_EPOCHS      = [16]              #unfreeze once (1-based epoch index)
MAX_UNFREEZE_GROUP   = 0                 #enable ONLY G0 (top approx. 12.5% near head)
LAYER_DECAY          = 0.7               #LR for group k: base_b * 0.7**k

@dataclass
class TrainHistory:
    epoch: List[int]
    train_loss: List[float]
    val_loss: List[float]
    train_f1: List[float]
    val_f1: List[float]
    lrs: List[float]

def class_weights_from_csv(csv_path, num_classes):
    df = pd.read_csv(csv_path)
    counts = df["class_idx"].value_counts().reindex(range(num_classes), fill_value=0).values.astype(np.float32)
    w = counts.sum() / (counts + 1e-6)
    w = w / w.mean()
    return torch.tensor(w, dtype=torch.float32)

def make_warmup_cosine(epochs_warmup, epochs_total, base_lr, min_lr):
    def step(ep):
        if ep < epochs_warmup:
            s = float(ep + 1) / max(1, epochs_warmup)
            return base_lr * s
        t = (ep - epochs_warmup) / max(1, epochs_total - epochs_warmup)
        return min_lr + (base_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * t))
    return step

#BatchNorm freezing helper
def _set_bn_eval(m):
    if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.SyncBatchNorm)):
        m.eval()
        for p in m.parameters():
            p.requires_grad = False

@torch.no_grad()
def evaluate_ce(model, loader, device, ce_loss):
    model.eval()
    run_ce, n = 0.0, 0
    y_true_all, y_pred_all = [], []
    for xb, yb, _ in tqdm(loader, desc="Valid", leave=False):
        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)
        logits = model(xb)
        loss_ce = ce_loss(logits, yb)
        b = xb.size(0); run_ce += loss_ce.item() * b; n += b
        preds = torch.argmax(logits, dim=1)
        y_true_all.append(yb.detach().cpu().numpy())
        y_pred_all.append(preds.detach().cpu().numpy())
    avg_ce = run_ce / max(1, n)
    macro_f1 = f1_score(np.concatenate(y_true_all), np.concatenate(y_pred_all), average="macro")
    return avg_ce, macro_f1

#NumPy-free param chunking to avoid CUDA and NumPy issues
def split_backbone_groups(backbone_params, groups=8):
    """
    Return [G0..G{groups-1}] where:
      - G0 contains params closest to the head (last in param order),
      - G{groups-1} contains earliest/stem params.
    """
    arr = list(backbone_params)
    n = len(arr)
    if n == 0:
        return [[] for _ in range(groups)]
    base = n // groups
    rem = n % groups
    chunks, start = [], 0
    for g in range(groups):
        size = base + (1 if g < rem else 0)
        end = start + size
        chunks.append(arr[start:end])
        start = end
    return chunks[::-1]  #reverse so G0 is nearest the head

def set_group_requires_grad(groups, up_to_idx):
    """Enable grads for groups [0..up_to_idx], keep the rest frozen."""
    for gi, plist in enumerate(groups):
        req = gi <= up_to_idx
        for p in plist:
            p.requires_grad = req

def set_group_lrs(optimizer, base_head_lr, base_backbone_lr, layer_decay, num_groups):
    optimizer.param_groups[0]["lr"] = base_head_lr  #head group
    for gi in range(num_groups):
        optimizer.param_groups[1 + gi]["lr"] = base_backbone_lr * (layer_decay ** gi)

def train_one_run(
    timm_name: str,
    pretty_name: str,
    fold_id: int,
    train_csv,
    val_csv,
    weight_decay_head: float = 0.01,
    weight_decay_backbone: float = 0.01,
):
    run_tag = f"{pretty_name}_fold{fold_id}"
    out_ckpt_dir = CKPT_ROOT / pretty_name.replace(" ", "_")
    out_run_dir  = RUNS_ROOT / pretty_name.replace(" ", "_")
    out_ckpt_dir.mkdir(parents=True, exist_ok=True)
    out_run_dir.mkdir(parents=True, exist_ok=True)

    #Data
    train_ds = CachedGBDDataset(train_csv, transform=train_tf)
    val_ds   = CachedGBDDataset(val_csv,   transform=eval_tf)
    num_classes = int(max(train_ds.df["class_idx"].max(), val_ds.df["class_idx"].max()) + 1)
    print(f"[{run_tag}] C={num_classes} | train={len(train_ds)} | val={len(val_ds)}")

    dl_train = dict(batch_size=BATCH_SIZE_MICRO, shuffle=True,
                    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True)   #even batch for MixUp
    dl_val   = dict(batch_size=BATCH_SIZE_MICRO, shuffle=False,
                    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)
    if NUM_WORKERS > 0:
        dl_train.update(prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT_WORKERS)
        dl_val.update(prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT_WORKERS)
    train_loader = DataLoader(train_ds, **dl_train)
    val_loader   = DataLoader(val_ds,   **dl_val)

    #Model
    model = build_model(timm_name, num_classes=num_classes).to(device)
    is_vit = "vit" in timm_name.lower()
    if SPEED_MODE and not is_vit:
        model = model.to(memory_format=torch.channels_last)

    #Split head/backbone
    head_module, head_params, backbone_params = split_params_head_backbone(model)

    #Save init backbone weights for L2-SP
    backbone_init = [p.detach().clone().to(device) for p in backbone_params]
    for p in backbone_init: p.requires_grad = False

    #Build contiguous backbone groups (G0 = nearest head)
    bb_groups = split_backbone_groups(backbone_params, groups=BACKBONE_GROUPS)

    #Linear probe: freeze full backbone
    for p in backbone_params: p.requires_grad = False
    for p in head_params:     p.requires_grad = True

    #Freeze BN stats in backbone (all training)
    if not is_vit:
        model.apply(_set_bn_eval)

    #LRs (very low backbone); long warmup for ViT
    BASE_LR_HEAD     = 3e-4
    BASE_LR_BACKBONE = 1e-6 if not is_vit else 5e-7
    MIN_LR_HEAD      = 1e-6
    MIN_LR_BACKBONE  = 5e-7
    warmup_epochs    = 10 if is_vit else 8

    #Optimiser with head + one param group per backbone group
    param_groups = [{"params": head_params, "lr": BASE_LR_HEAD, "weight_decay": weight_decay_head}]
    for gi, plist in enumerate(bb_groups):
        lr = BASE_LR_BACKBONE * (LAYER_DECAY ** gi)
        param_groups.append({"params": plist, "lr": lr, "weight_decay": weight_decay_backbone})
    optimizer = torch.optim.AdamW(param_groups)

    sched_head = make_warmup_cosine(warmup_epochs, EPOCHS, BASE_LR_HEAD, MIN_LR_HEAD)
    sched_back = make_warmup_cosine(warmup_epochs, EPOCHS, BASE_LR_BACKBONE, MIN_LR_BACKBONE)

    #Losses
    if USE_MIXUP and _HAS_MIXUP:
        mixup_fn = Mixup(mixup_alpha=MIXUP_ALPHA, cutmix_alpha=0.0,
                         prob=MIXUP_PROB, switch_prob=0.0, mode='elem',
                         label_smoothing=0.0, num_classes=num_classes)
        soft_ce = SoftTargetCrossEntropy()
        ce_tr   = None
        ce_val  = nn.CrossEntropyLoss()          #for reporting
    else:
        mixup_fn = None
        weights = class_weights_from_csv(train_csv, num_classes).to(device)
        ce_tr   = nn.CrossEntropyLoss(weight=weights, label_smoothing=LABEL_SMOOTH)
        ce_val  = nn.CrossEntropyLoss()

    scaler = torch.amp.GradScaler('cuda', enabled=MIXED_PRECISION)

    #Unfreeze schedule: at epoch 16 (1-based), enable only G0 (approx. 12.5% near head)
    unfreeze_at = {UNFREEZE_EPOCHS[0]: MAX_UNFREEZE_GROUP}

    hist = TrainHistory(epoch=[], train_loss=[], val_loss=[], train_f1=[], val_f1=[], lrs=[])
    best_f1, best_epoch, no_improve = -1.0, -1, 0

    for epoch in range(EPOCHS):
        #Apply scheduled unfreezing
        if (epoch+1) in unfreeze_at:
            up_to = unfreeze_at[epoch+1]
            set_group_requires_grad(bb_groups, up_to_idx=up_to)   #enables G0 only
            tqdm.write(f"[{run_tag}]  Unfroze backbone groups G0..G{up_to} at epoch {epoch+1}")

        #Update LRs (head + layer-decayed backbone groups)
        lr_h = sched_head(epoch)
        lr_b_base = sched_back(epoch)
        set_group_lrs(optimizer, lr_h, lr_b_base, LAYER_DECAY, len(bb_groups))

        #Train
        model.train()
        optimizer.zero_grad(set_to_none=True)
        run_loss, n = 0.0, 0
        y_true_tr, y_pred_tr = [], []

        pbar = tqdm(train_loader, desc=f"Train {run_tag} — epoch {epoch+1}/{EPOCHS}", leave=False)
        for step, (xb, yb, _) in enumerate(pbar, start=1):
            xb = xb.to(device, non_blocking=True)
            if SPEED_MODE and not is_vit:
                xb = xb.to(memory_format=torch.channels_last)
            yb = yb.to(device, non_blocking=True)

            if mixup_fn is not None:
                xb, yb_mix = mixup_fn(xb, yb)

            with torch.amp.autocast('cuda', enabled=MIXED_PRECISION):
                logits = model(xb)
                if mixup_fn is not None:
                    loss_main = soft_ce(logits, yb_mix)
                else:
                    loss_main = ce_tr(logits, yb)

                #L2-SP on any unfrozen backbone params
                l2sp = 0.0
                for p, p0 in zip(backbone_params, backbone_init):
                    if p.requires_grad:
                        d = (p - p0)
                        l2sp += d.pow(2).sum()
                loss = (loss_main + L2SP_LAMBDA * l2sp) / ACCUM_STEPS

            scaler.scale(loss).backward()

            if step % ACCUM_STEPS == 0 or step == len(train_loader):
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)
                scaler.step(optimizer); scaler.update()
                optimizer.zero_grad(set_to_none=True)

            run_loss += loss_main.item() * xb.size(0) * ACCUM_STEPS
            n += xb.size(0)

            preds = torch.argmax(logits.detach(), dim=1)
            y_true_tr.append(yb.detach().cpu().numpy())
            y_pred_tr.append(preds.cpu().numpy())
            pbar.set_postfix_str(f"loss={loss_main.item():.4f} lr_h={lr_h:.1e} lr_b={lr_b_base:.1e}")

        train_loss = run_loss / max(1, n)
        train_f1 = f1_score(np.concatenate(y_true_tr), np.concatenate(y_pred_tr), average="macro")

        #Validate
        val_loss, val_f1 = evaluate_ce(model, val_loader, device, ce_val)

        #Log
        hist.epoch.append(epoch+1)
        hist.train_loss.append(train_loss)
        hist.val_loss.append(val_loss)
        hist.train_f1.append(train_f1)
        hist.val_f1.append(val_f1)
        hist.lrs.append(lr_h)

        tqdm.write(f"[{run_tag}] Epoch {epoch+1:02d} | "
                   f"train_loss={train_loss:.4f} val_loss={val_loss:.4f} | "
                   f"train_f1={train_f1:.4f} val_f1={val_f1:.4f}")

        improved = val_f1 > best_f1 + 1e-6
        if improved:
            best_f1, best_epoch, no_improve = val_f1, epoch+1, 0
            ckpt_path = out_ckpt_dir / f"{pretty_name.replace(' ','_')}_fold{fold_id}_best.pt"
            torch.save({
                "model_name": timm_name,
                "pretty_name": pretty_name,
                "state_dict": model.state_dict(),
                "optimizer": optimizer.state_dict(),
                "epoch": best_epoch,
                "num_classes": num_classes,
                "img_size": IMG_SIZE,
                "history": asdict(hist),
            }, ckpt_path)
            tqdm.write(f"[{run_tag}]  Saved best checkpoint: {ckpt_path}")
        else:
            no_improve += 1

        if no_improve >= PATIENCE:
            tqdm.write(f"[{run_tag}] Early stopping (no val F1 improvement for {PATIENCE} epochs).")
            break

        torch.cuda.empty_cache(); gc.collect()

    #Curves
    plot_curves(hist, out_run_dir, run_tag)
    return best_f1, best_epoch

"""Train loader (NO MixUp, weighted sampler, top-only unfreeze) FINAL"""

#T7: Trainer (no MixUp, weighted sampler, top-only unfreeze)
import math, gc, torch, numpy as np, pandas as pd
import torch.nn as nn
from dataclasses import dataclass, asdict
from typing import List
from tqdm.auto import tqdm
from sklearn.metrics import f1_score
from torch.utils.data import DataLoader, WeightedRandomSampler

#Unfreeze plan (keep very conservative)
L2SP_LAMBDA        = 5e-4
BACKBONE_GROUPS    = 8        # approx. 12.5% per group
UNFREEZE_EPOCHS    = [16]     #enable only top group at epoch 16
MAX_UNFREEZE_GROUP = 0
LAYER_DECAY        = 0.7

@dataclass
class TrainHistory:
    epoch: List[int]
    train_loss: List[float]
    val_loss: List[float]
    train_f1: List[float]
    val_f1: List[float]
    lrs: List[float]

def class_weights_from_csv(csv_path, num_classes):
    df = pd.read_csv(csv_path)
    counts = df["class_idx"].value_counts().reindex(range(num_classes), fill_value=0).values.astype(np.float32)
    w = counts.sum() / (counts + 1e-6)
    w = w / w.mean()
    return torch.tensor(w, dtype=torch.float32)

def make_warmup_cosine(epochs_warmup, epochs_total, base_lr, min_lr):
    def step(ep):
        if ep < epochs_warmup:
            s = float(ep + 1) / max(1, epochs_warmup)
            return base_lr * s
        t = (ep - epochs_warmup) / max(1, epochs_total - epochs_warmup)
        return min_lr + (base_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * t))
    return step

def _set_bn_eval(m):
    if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.SyncBatchNorm)):
        m.eval()
        for p in m.parameters():
            p.requires_grad = False

@torch.no_grad()
def evaluate_ce(model, loader, device, ce_loss):
    model.eval()
    run_ce, n = 0.0, 0
    y_true_all, y_pred_all = [], []
    for xb, yb, _ in tqdm(loader, desc="Valid", leave=False):
        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)
        logits = model(xb)
        loss_ce = ce_loss(logits, yb)
        b = xb.size(0); run_ce += loss_ce.item() * b; n += b
        preds = torch.argmax(logits, dim=1)
        y_true_all.append(yb.detach().cpu().numpy())
        y_pred_all.append(preds.detach().cpu().numpy())
    avg_ce = run_ce / max(1, n)
    macro_f1 = f1_score(np.concatenate(y_true_all), np.concatenate(y_pred_all), average="macro")
    return avg_ce, macro_f1

def split_backbone_groups(backbone_params, groups=8):
    arr = list(backbone_params)
    n = len(arr)
    if n == 0:
        return [[] for _ in range(groups)]
    base = n // groups
    rem = n % groups
    chunks, start = [], 0
    for g in range(groups):
        size = base + (1 if g < rem else 0)
        end = start + size
        chunks.append(arr[start:end])
        start = end
    return chunks[::-1]  #G0 is nearest head

def set_group_requires_grad(groups, up_to_idx):
    for gi, plist in enumerate(groups):
        req = gi <= up_to_idx
        for p in plist:
            p.requires_grad = req

def set_group_lrs(optimizer, base_head_lr, base_backbone_lr, layer_decay, num_groups):
    optimizer.param_groups[0]["lr"] = base_head_lr
    for gi in range(num_groups):
        optimizer.param_groups[1 + gi]["lr"] = base_backbone_lr * (layer_decay ** gi)

def _make_weighted_sampler(train_df, num_classes):
    counts = train_df["class_idx"].value_counts().reindex(range(num_classes), fill_value=0).values.astype(float)
    class_w = counts.sum() / (counts + 1e-6)
    class_w = class_w / class_w.mean()
    w_map   = {i: class_w[i] for i in range(num_classes)}
    sample_w = train_df["class_idx"].map(w_map).astype(float).values
    return WeightedRandomSampler(torch.DoubleTensor(sample_w), num_samples=len(sample_w), replacement=True)

def train_one_run(
    timm_name: str,
    pretty_name: str,
    fold_id: int,
    train_csv,
    val_csv,
    weight_decay_head: float = 0.01,
    weight_decay_backbone: float = 0.01,
):
    run_tag = f"{pretty_name}_fold{fold_id}"
    out_ckpt_dir = CKPT_ROOT / pretty_name.replace(" ", "_")
    out_run_dir  = RUNS_ROOT / pretty_name.replace(" ", "_")
    out_ckpt_dir.mkdir(parents=True, exist_ok=True)
    out_run_dir.mkdir(parents=True, exist_ok=True)

    #Data
    train_ds = CachedGBDDataset(train_csv, transform=train_tf)
    val_ds   = CachedGBDDataset(val_csv,   transform=eval_tf)
    num_classes = int(max(train_ds.df["class_idx"].max(), val_ds.df["class_idx"].max()) + 1)
    print(f"[{run_tag}] C={num_classes} | train={len(train_ds)} | val={len(val_ds)}")

    #Loaders (sampler for train only)
    common_train = dict(batch_size=BATCH_SIZE_MICRO, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)
    common_val   = dict(batch_size=BATCH_SIZE_MICRO, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)
    if NUM_WORKERS > 0:
        common_train.update(prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT_WORKERS)
        common_val.update(prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT_WORKERS)

    if USE_WEIGHTED_SAMPLER:
        sampler = _make_weighted_sampler(train_ds.df, num_classes)
        train_loader = DataLoader(train_ds, sampler=sampler, shuffle=False, **common_train)
    else:
        train_loader = DataLoader(train_ds, shuffle=True, **common_train)
    val_loader = DataLoader(val_ds, shuffle=False, **common_val)

    #Model
    model = build_model(timm_name, num_classes=num_classes).to(device)
    is_vit = "vit" in timm_name.lower()
    if SPEED_MODE and not is_vit:
        model = model.to(memory_format=torch.channels_last)

    #Head/backbone split
    head_module, head_params, backbone_params = split_params_head_backbone(model)

    #L2-SP anchor
    backbone_init = [p.detach().clone().to(device) for p in backbone_params]
    for p in backbone_init: p.requires_grad = False

    #Contiguous param groups for backbone (G0 near head)
    bb_groups = split_backbone_groups(backbone_params, groups=BACKBONE_GROUPS)

    #Linear probe: freeze backbone, train head
    for p in backbone_params: p.requires_grad = False
    for p in head_params:     p.requires_grad = True

    #Frozen BN in backbone
    if not is_vit:
        model.apply(_set_bn_eval)

    #LRs and warmup
    BASE_LR_HEAD     = 3e-4
    BASE_LR_BACKBONE = 1e-6 if not is_vit else 5e-7
    MIN_LR_HEAD      = 1e-6
    MIN_LR_BACKBONE  = 5e-7
    warmup_epochs    = 10 if is_vit else 8

    #Optimizer: head + one group per backbone chunk
    param_groups = [{"params": head_params, "lr": BASE_LR_HEAD, "weight_decay": weight_decay_head}]
    for gi, plist in enumerate(bb_groups):
        lr = BASE_LR_BACKBONE * (LAYER_DECAY ** gi)
        param_groups.append({"params": plist, "lr": lr, "weight_decay": weight_decay_backbone})
    optimizer = torch.optim.AdamW(param_groups)

    sched_head = make_warmup_cosine(warmup_epochs, EPOCHS, BASE_LR_HEAD, MIN_LR_HEAD)
    sched_back = make_warmup_cosine(warmup_epochs, EPOCHS, BASE_LR_BACKBONE, MIN_LR_BACKBONE)

    #Losses: class-weighted CE + label smoothing
    weights = class_weights_from_csv(train_csv, num_classes).to(device)
    ce_tr   = nn.CrossEntropyLoss(weight=weights, label_smoothing=LABEL_SMOOTH)
    ce_val  = nn.CrossEntropyLoss()

    scaler = torch.amp.GradScaler('cuda', enabled=MIXED_PRECISION)
    unfreeze_at = {UNFREEZE_EPOCHS[0]: MAX_UNFREEZE_GROUP}

    hist = TrainHistory(epoch=[], train_loss=[], val_loss=[], train_f1=[], val_f1=[], lrs=[])
    best_f1, best_epoch, no_improve = -1.0, -1, 0

    for epoch in range(EPOCHS):
        #Scheduled unfreeze (top-only)
        if (epoch+1) in unfreeze_at:
            up_to = unfreeze_at[epoch+1]
            set_group_requires_grad(bb_groups, up_to_idx=up_to)
            tqdm.write(f"[{run_tag}]  Unfroze backbone groups G0..G{up_to} at epoch {epoch+1}")

        #Update LRs
        lr_h = sched_head(epoch)
        lr_b_base = sched_back(epoch)
        set_group_lrs(optimizer, lr_h, lr_b_base, LAYER_DECAY, len(bb_groups))

        #Train
        model.train()
        optimizer.zero_grad(set_to_none=True)
        run_loss, n = 0.0, 0
        y_true_tr, y_pred_tr = [], []

        pbar = tqdm(train_loader, desc=f"Train {run_tag} — epoch {epoch+1}/{EPOCHS}", leave=False)
        for step, (xb, yb, _) in enumerate(pbar, start=1):
            xb = xb.to(device, non_blocking=True)
            if SPEED_MODE and not is_vit:
                xb = xb.to(memory_format=torch.channels_last)
            yb = yb.to(device, non_blocking=True)

            with torch.amp.autocast('cuda', enabled=MIXED_PRECISION):
                logits = model(xb)
                loss_main = ce_tr(logits, yb)

                #L2-SP on any unfrozen backbone params
                l2sp = 0.0
                for p, p0 in zip(backbone_params, backbone_init):
                    if p.requires_grad:
                        d = (p - p0)
                        l2sp += d.pow(2).sum()
                loss = (loss_main + L2SP_LAMBDA * l2sp) / ACCUM_STEPS

            scaler.scale(loss).backward()

            if step % ACCUM_STEPS == 0 or step == len(train_loader):
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)
                scaler.step(optimizer); scaler.update()
                optimizer.zero_grad(set_to_none=True)

            run_loss += loss_main.item() * xb.size(0) * ACCUM_STEPS
            n += xb.size(0)

            preds = torch.argmax(logits.detach(), dim=1)
            y_true_tr.append(yb.detach().cpu().numpy())
            y_pred_tr.append(preds.cpu().numpy())
            pbar.set_postfix_str(f"loss={loss_main.item():.4f} lr_h={lr_h:.1e} lr_b={lr_b_base:.1e}")

        train_loss = run_loss / max(1, n)
        train_f1 = f1_score(np.concatenate(y_true_tr), np.concatenate(y_pred_tr), average="macro")

        #Validate
        val_loss, val_f1 = evaluate_ce(model, val_loader, device, ce_val)

        #Log
        hist.epoch.append(epoch+1)
        hist.train_loss.append(train_loss)
        hist.val_loss.append(val_loss)
        hist.train_f1.append(train_f1)
        hist.val_f1.append(val_f1)
        hist.lrs.append(lr_h)

        tqdm.write(f"[{run_tag}] Epoch {epoch+1:02d} | train_loss={train_loss:.4f} val_loss={val_loss:.4f} | "
                   f"train_f1={train_f1:.4f} val_f1={val_f1:.4f}")

        improved = val_f1 > best_f1 + 1e-6
        if improved:
            best_f1, best_epoch, no_improve = val_f1, epoch+1, 0
            ckpt_path = out_ckpt_dir / f"{pretty_name.replace(' ','_')}_fold{fold_id}_best.pt"
            torch.save({
                "model_name": timm_name,
                "pretty_name": pretty_name,
                "state_dict": model.state_dict(),
                "optimizer": optimizer.state_dict(),
                "epoch": best_epoch,
                "num_classes": num_classes,
                "img_size": IMG_SIZE,
                "history": asdict(hist),
            }, ckpt_path)
            tqdm.write(f"[{run_tag}]  Saved best checkpoint: {ckpt_path}")
        else:
            no_improve += 1

        if no_improve >= PATIENCE:
            tqdm.write(f"[{run_tag}] Early stopping (no val F1 improvement for {PATIENCE} epochs).")
            break

        torch.cuda.empty_cache(); gc.collect()

    #Curves (uses your existing plot_curves)
    plot_curves(hist, out_run_dir, run_tag)
    return best_f1, best_epoch

"""5.8. Launch training."""

#T8: Launch training (aligned with new train_one_run signature)
from pathlib import Path
import pandas as pd
import gc, torch
import matplotlib.pyplot as plt

#Controls:
SKIP_IF_EXISTS     = False   #True = skip runs that already have a _best.pt
OVERWRITE_EXISTING = True    #True = delete existing best/last + logs before retraining
CLEAR_RUN_LOGS     = True    #True = remove old plots/CSV for the folds you retrain

results = []

for fold_id in FOLDS_TO_TRAIN:
    fold_dir = SPLITS_ROOT / f"fold_{fold_id}"
    train_csv = fold_dir / "train.csv"
    val_csv   = fold_dir / "val.csv"
    assert train_csv.exists() and val_csv.exists(), f"Missing CSVs for fold {fold_id}"

    for timm_name, pretty_name in MODELS_TO_TRAIN:
        ckpt_dir   = CKPT_ROOT / pretty_name.replace(" ", "_")
        ckpt_dir.mkdir(parents=True, exist_ok=True)
        best_path  = ckpt_dir / f"{pretty_name.replace(' ','_')}_fold{fold_id}_best.pt"
        last_path  = ckpt_dir / f"{pretty_name.replace(' ','_')}_fold{fold_id}_last.pt"

        #Skip logic (if not overwriting)
        if not OVERWRITE_EXISTING and SKIP_IF_EXISTS and best_path.exists():
            print(f"  Skipping {pretty_name} fold {fold_id} — checkpoint exists:\n    {best_path}")
            continue

        #Overwrite logic: clean old checkpoints/logs for this run
        if OVERWRITE_EXISTING:
            for p in [best_path, last_path]:
                if p.exists():
                    p.unlink()
            if CLEAR_RUN_LOGS:
                run_dir = RUNS_ROOT / pretty_name.replace(" ", "_")
                # remove old plots/CSV for this fold only
                for suffix in ["_loss.png", "_macroF1.png", "_history.csv"]:
                    fp = run_dir / f"{pretty_name.replace(' ','_')}_fold{fold_id}{suffix}"
                    if fp.exists():
                        fp.unlink()

        print(f"\n===== Training {pretty_name} on fold {fold_id} =====")
        #NEW signature: no base_lr/min_lr; optional per-group weight_decay only
        best_f1, best_epoch = train_one_run(
            timm_name=timm_name,
            pretty_name=pretty_name,
            fold_id=fold_id,
            train_csv=train_csv,
            val_csv=val_csv,
            #(optional) tweak weight decay per family:
            weight_decay_head=0.01,
            weight_decay_backbone=(0.05 if "vit" in timm_name.lower() else 0.01),
        )

        results.append({
            "model": pretty_name,
            "fold": fold_id,
            "best_val_macro_f1": best_f1,
            "best_epoch": best_epoch
        })
        torch.cuda.empty_cache(); gc.collect()

#Save/append summary
summary_path = RUNS_ROOT / "training_summary.csv"
df_new = pd.DataFrame(results)
if df_new.empty and summary_path.exists():
    print("\nNothing newly trained (possibly all runs were skipped).")
    display(pd.read_csv(summary_path))
else:
    if summary_path.exists():
        df_old = pd.read_csv(summary_path)
        df_out = pd.concat([df_old, df_new], ignore_index=True)
    else:
        df_out = df_new
    df_out.to_csv(summary_path, index=False)
    print("\n[DONE] Training summary:")
    display(df_out)
    print(f"[OK] Saved/updated: {summary_path}")

"""#6. Evaluation and Testing"""

#0. Installs + imports
!pip -q install timm==0.9.16 pytorch-grad-cam==1.5.0 scikit-learn==1.4.2

from google.colab import drive
drive.mount('/content/drive')

import os, math, json, itertools, warnings, pathlib
from typing import Optional, Tuple
import numpy as np
import pandas as pd
import cv2
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import timm

from sklearn.metrics import (
    confusion_matrix, precision_recall_fscore_support,
    precision_recall_curve, average_precision_score
)

import matplotlib.pyplot as plt
plt.rcParams["figure.dpi"] = 120
warnings.filterwarnings("ignore", category=UserWarning)

# 1. CONFIG — << EDIT THESE PATHS IF YOU TEST AND RUN THE CODE>>

# Path to your saved model (expects RGB, GhostNet-1.0, fold 5)
MODEL_PATH = "/content/drive/MyDrive/AI/Project_Summer_Module/Best Model/GhostNet-1.0_fold5_best.pt" #This is where the best model was saved.

#Location of the manifest created earlier in the notebook
SPLITS_ROOT = "/content/drive/MyDrive/AI/Project_Summer_Module/splits_5fold_v1"  #folder that contains test.csv (+ meta.json)
TEST_CSV = f"{SPLITS_ROOT}/test.csv"                                    #produced earlier when splitting the data.
META_JSON = f"{SPLITS_ROOT}/meta.json"                                   #optional (img_size lives here)

#Output folder for all figures/CSVs from this evaluation
OUT_DIR = "/content/drive/MyDrive/AI/Project_Summer_Module/ghostnet_fold5_test_eval"
os.makedirs(OUT_DIR, exist_ok=True)

#In case meta.json is missing, fall back to this size (match training)
DEFAULT_IMG_SIZE = 224
BATCH_SIZE = 64
NUM_WORKERS = 2
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

print(f"[CONFIG] MODEL_PATH: {MODEL_PATH}")
print(f"[CONFIG] TEST_CSV : {TEST_CSV}")
print(f"[CONFIG] META_JSON: {META_JSON}")
print(f"[CONFIG] OUT_DIR  : {OUT_DIR}")

#2. Utilities: read meta, image I/O helpers

def read_meta_img_size(meta_path: str, default_size: int = 224) -> int:
    """Read IMG_SIZE from meta.json if available, else return a sensible default."""
    if os.path.isfile(meta_path):
        with open(meta_path, "r") as f:
            meta = json.load(f)
        return int(meta.get("img_size", default_size))
    return default_size

def load_rgb_image(path: str) -> Image.Image:
    """
    Robust image loader:
      - supports standard image files readable by PIL,
      - if a .npy cache is provided (single-channel or 3-ch), convert to RGB visually.
    Always return a PIL.Image in RGB.
    """
    p = str(path)
    if p.lower().endswith(".npy"):
        arr = np.load(p)
        #If grayscale [H,W], expand; if [H,W,1], squeeze; if [H,W,3] keep.
        if arr.ndim == 2:
            arr = np.stack([arr, arr, arr], axis=-1)
        elif arr.ndim == 3 and arr.shape[2] == 1:
            arr = np.repeat(arr, 3, axis=2)
        elif arr.ndim == 3 and arr.shape[2] >= 3:
            arr = arr[..., :3]
        arr = np.clip(arr, 0, 255).astype(np.uint8)
        return Image.fromarray(arr, mode="RGB")
    else:
        #PIL path
        img = Image.open(p).convert("RGB")
        return img

#3. Dataset from your manifest (patient-level test set)
#     - will use cache_path if present, else filepath
#     - converts to RGB (model expects 3-ch)
#     - applies ImageNet normalisation used by most timm backbones

from torchvision import transforms

IMG_SIZE = read_meta_img_size(META_JSON, default_size=DEFAULT_IMG_SIZE)
print(f"[META] Using IMG_SIZE={IMG_SIZE}")

test_tfms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std =[0.229, 0.224, 0.225]),
])

class ManifestDataset(Dataset):
    def __init__(self, df: pd.DataFrame, transform=None):
        self.df = df.reset_index(drop=True)
        self.transform = transform
        #build ordered class name list by class_idx to keep consistent mapping
        #(e.g., idx 0 -> name class_names[0])
        classes = self.df[["class_idx","class"]].drop_duplicates().sort_values("class_idx")
        self.class_names = classes["class"].tolist()
        self.num_classes = len(self.class_names)

    def __len__(self):
        return len(self.df)

    def __getitem__(self, i):
        row = self.df.iloc[i]
        #choose cache if present else original filepath
        img_path = row["cache_path"] if pd.notna(row["cache_path"]) else row["filepath"]
        img = load_rgb_image(img_path)      # PIL RGB
        y = int(row["class_idx"])
        if self.transform:
            img = self.transform(img)
        return img, y, str(img_path)

#Load test manifest
df_test = pd.read_csv(TEST_CSV)
test_ds = ManifestDataset(df_test, transform=test_tfms)
class_names = test_ds.class_names
num_classes = test_ds.num_classes

test_loader = DataLoader(
    test_ds, batch_size=BATCH_SIZE, shuffle=False,
    num_workers=NUM_WORKERS, pin_memory=True
)

print(f"[DATA] Test samples: {len(test_ds)} | Classes ({num_classes}): {class_names}")

#4. Model: GhostNet-1.0 (RGB) + checkpoint loader (robust to prefixes)

def strip_prefix_if_present(state_dict, prefixes=("module.", "model.")):
    new_sd = {}
    for k, v in state_dict.items():
        nk = k
        for p in prefixes:
            if nk.startswith(p):
                nk = nk[len(p):]
        new_sd[nk] = v
    return new_sd

#Create the architecture (1.0x width)
model = timm.create_model(
    "ghostnet_100",
    pretrained=False,
    num_classes=num_classes,
    in_chans=3  #RGB
).to(DEVICE)

#Load weights
ckpt = torch.load(MODEL_PATH, map_location=DEVICE)
state_dict = ckpt.get("state_dict", ckpt)
state_dict = strip_prefix_if_present(state_dict)
missing, unexpected = model.load_state_dict(state_dict, strict=False)
print(f"[MODEL] Loaded. Missing: {len(missing)} | Unexpected: {len(unexpected)}")
model.eval();

#5. Forward pass over TEST: collect logits/probs/labels/paths

@torch.inference_mode()
def collect_outputs(m, loader, device=DEVICE):
    all_logits, all_probs, all_y, all_paths = [], [], [], []
    for images, targets, paths in loader:
        images = images.to(device, non_blocking=True)
        logits = m(images)
        probs  = F.softmax(logits, dim=1)

        all_logits.append(logits.cpu())
        all_probs.append(probs.cpu())
        all_y.append(targets.clone())
        all_paths.extend(list(paths))

    logits = torch.cat(all_logits)
    probs  = torch.cat(all_probs)
    y_true = torch.cat(all_y)
    y_pred = probs.argmax(dim=1)
    return logits, probs, y_true, y_pred, all_paths

logits, probs, y_true, y_pred, img_paths = collect_outputs(model, test_loader)
print("Shapes:", logits.shape, probs.shape, y_true.shape, y_pred.shape)

#6. Metrics: Macro-F1 and per-class metrics (precision/recall/F1/specificity)

y_true_np = y_true.numpy()
y_pred_np = y_pred.numpy()

#Standard per-class metrics
prec, rec, f1, support = precision_recall_fscore_support(
    y_true_np, y_pred_np, labels=np.arange(num_classes), average=None, zero_division=0
)

macro_f1 = float(np.mean(f1))

#Specificity from confusion matrix
cm = confusion_matrix(y_true_np, y_pred_np, labels=np.arange(num_classes))
specificity = []
for c in range(num_classes):
    TP = cm[c, c]
    FP = cm[:, c].sum() - TP
    FN = cm[c, :].sum() - TP
    TN = cm.sum() - (TP + FP + FN)
    spec = TN / (TN + FP) if (TN + FP) > 0 else 0.0
    specificity.append(spec)

metrics_df = pd.DataFrame({
    "class": class_names,
    "support": support,
    "precision": prec,
    "recall": rec,
    "f1": f1,
    "specificity": specificity
})

print(f"\n[RESULT] Averaged Macro-F1 (TEST): {macro_f1:.4f}")
display(metrics_df)

#Save CSV
metrics_csv = f"{OUT_DIR}/per_class_metrics.csv"
metrics_df.to_csv(metrics_csv, index=False)
print(f"[SAVE] {metrics_csv}")

#7. Confusion Matrix (normalised)

def plot_confusion_matrix(cm, classes, normalize=True, cmap="Blues", save_path=None):
    if normalize:
        with np.errstate(all='ignore'):
            cm = cm.astype("float") / cm.sum(axis=1, keepdims=True)
            cm = np.nan_to_num(cm)

    fig, ax = plt.subplots(figsize=(8, 6))
    im = ax.imshow(cm, interpolation="nearest", cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    ax.set(
        xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),
        xticklabels=classes, yticklabels=classes,
        ylabel="True label", xlabel="Predicted label",
        title=f"Confusion Matrix{' (normalised)' if normalize else ''}"
    )
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right")

    fmt = ".2f" if normalize else "d"
    thresh = cm.max() / 2.0
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        ax.text(j, i, format(cm[i, j], fmt),
                ha="center", va="center",
                color="white" if cm[i, j] > thresh else "black", fontsize=9)
    fig.tight_layout()
    if save_path:
        fig.savefig(save_path, bbox_inches="tight", dpi=200)
    plt.show()

cm_png = f"{OUT_DIR}/confusion_matrix.png"
plot_confusion_matrix(cm, class_names, normalize=True, save_path=cm_png)
print(f"[SAVE] {cm_png}")

#8. Precision–Recall Curves per class (+ AP)

y_prob = probs.numpy()
y_true_1hot = np.zeros((len(y_true_np), num_classes), dtype=np.int32)
y_true_1hot[np.arange(len(y_true_np)), y_true_np] = 1

rows = math.ceil(num_classes/3)
fig, axes = plt.subplots(rows, 3, figsize=(18, 5*rows))
axes = axes.ravel()

ap_scores = []
for c in range(num_classes):
    precision, recall, _ = precision_recall_curve(y_true_1hot[:, c], y_prob[:, c])
    ap = average_precision_score(y_true_1hot[:, c], y_prob[:, c])
    ap_scores.append(ap)

    ax = axes[c]
    ax.plot(recall, precision, lw=2)
    ax.set_title(f"{class_names[c]} — AP={ap:.3f}")
    ax.set_xlabel("Recall"); ax.set_ylabel("Precision")
    ax.grid(True, alpha=0.3)

#Hide any extra subplots
for k in range(num_classes, len(axes)):
    axes[k].axis("off")

plt.suptitle("Per-class Precision–Recall Curves", fontsize=14, y=1.02)
plt.tight_layout()
pr_png = f"{OUT_DIR}/pr_curves_per_class.png"
plt.savefig(pr_png, bbox_inches="tight", dpi=200)
plt.show()
print(f"[SAVE] {pr_png}")

#CELL: summary dump
summary = {
    "macro_f1": float(np.mean(metrics_df['f1'])),
    "num_classes": num_classes,
    "classes": class_names,
    "ap_per_class": {cls: float(ap) for cls, ap in zip(class_names, ap_scores)},
}
with open(os.path.join(OUT_DIR, "summary.json"), "w") as f:
    json.dump(summary, f, indent=2)

print(json.dumps(summary, indent=2))
print("\nArtifacts saved in:", OUT_DIR)

#Turn all nn.ReLU(inplace=True) into nn.ReLU(inplace=False)
import torch.nn as nn

def disable_inplace_relu(module: nn.Module):
    for name, child in module.named_children():
        if isinstance(child, nn.ReLU) and getattr(child, "inplace", False):
            setattr(module, name, nn.ReLU(inplace=False))
        else:
            disable_inplace_relu(child)

disable_inplace_relu(model)
model.eval()  # keep eval mode for CAM
print("[OK] Switched all in-place ReLU to out-of-place for CAM.")

#Grad-CAM++ (hook-safe version: no backward hooks)

import os, numpy as np, torch, torch.nn as nn, torch.nn.functional as F, cv2


def find_last_conv_layer(m):
    last = None
    for mod in m.modules():
        if isinstance(mod, nn.Conv2d):
            last = mod
    return last

target_layer = find_last_conv_layer(model)   #re-grab after patch
#(re)register the forward hook

#ImageNet de-normalisation for overlays
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406]).reshape(1,1,3)
IMAGENET_STD  = np.array([0.229, 0.224, 0.225]).reshape(1,1,3)
def denorm(img_t: torch.Tensor) -> np.ndarray:
    """img_t: (3,H,W) -> float RGB [0..1]"""
    img = img_t.permute(1,2,0).cpu().numpy()
    img = (img * IMAGENET_STD + IMAGENET_MEAN).clip(0,1)
    return img

#forward hook to capture feature maps (no detach; we need grads)
_fmaps = None
def _f_hook(_, __, output):
    global _fmaps
    _fmaps = output  #keeps graph so autograd.grad can flow

_fh = target_layer.register_forward_hook(_f_hook)

@torch.no_grad()
def collect_path_to_tensor(loader):
    m = {}
    for imgs, _, paths in loader:
        for t, p in zip(imgs, paths):
            m[p] = t  #normalised (3,H,W)
    return m

#Map each test image path to its input tensor (for display and re-run)
path_to_tensor = collect_path_to_tensor(test_loader)

def gradcam_pp_single(x: torch.Tensor, class_idx: int) -> np.ndarray:
    """
    x: (1,3,H,W) normalised, on DEVICE
    class_idx: target class index for CAM
    return: (H,W) CAM in [0,1]
    """
    global _fmaps
    _fmaps = None

    #Forward: populate _fmaps via hook (keep grads enabled)
    with torch.enable_grad():
        logits = model(x)                 #(1, C)
        score = logits[0, class_idx]      #scalar

        #grads w.r.t. hooked activations
        assert _fmaps is not None, "Hook did not capture activations."
        grads = torch.autograd.grad(score, _fmaps, retain_graph=False, create_graph=False)[0]

        A = _fmaps                        #(1, K, h, w)
        g = grads
        g2, g3 = g * g, g * g * g
        eps = 1e-7

        #Grad-CAM++ weights
        alpha = g2 / (2.0 * g2 + A * g3 + eps)
        w = (alpha * torch.clamp(g, min=0.0)).sum(dim=(2, 3))  #(1, K)

        cam = torch.einsum("nk,nkhw->nhw", w, A)               #(1, h, w)
        cam = torch.clamp(cam, min=0.0)[0]                     #(h, w)

        cam = F.interpolate(cam.unsqueeze(0).unsqueeze(0),
                            size=(x.shape[2], x.shape[3]),
                            mode="bilinear", align_corners=False)[0, 0]

    cam = cam.detach().cpu().numpy()                           #detach before numpy()
    cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-7)
    return cam


#Choose a few confident examples (correct and incorrect)
prob_max, _ = probs.max(dim=1)
correct_mask = (y_pred == y_true)
incorrect_mask = ~correct_mask

K = 6
sel_correct = (torch.where(correct_mask)[0]
               [prob_max[correct_mask].topk(min(K, correct_mask.sum().item())).indices].tolist()
               if correct_mask.any() else [])
sel_incorrect = (torch.where(incorrect_mask)[0]
                 [prob_max[incorrect_mask].topk(min(K, incorrect_mask.sum().item())).indices].tolist()
                 if incorrect_mask.any() else [])
chosen = sel_correct + sel_incorrect
print(f"[CAM++] Visualising {len(chosen)} images "
      f"({len(sel_correct)} correct + {len(sel_incorrect)} incorrect).")

cam_dir = os.path.join(OUT_DIR, "gradcampp")
os.makedirs(cam_dir, exist_ok=True)

#Generate and save overlays
for idx in chosen:
    p = img_paths[idx]
    t = path_to_tensor[p]                  #(3,H,W) normalised
    x = t.unsqueeze(0).to(DEVICE)

    cam = gradcam_pp_single(x, int(y_pred[idx].item()))  #predicted class
    base_rgb = denorm(t)                                   #(H,W,3), [0,1]

    heat = (cam * 255).astype(np.uint8)
    heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)[:, :, ::-1] / 255.0  #RGB [0..1]
    overlay = (0.5 * base_rgb + 0.5 * heat).clip(0, 1)
    overlay_u8 = (overlay * 255).astype(np.uint8)

    pred_c = int(y_pred[idx].item())
    true_c = int(y_true[idx].item())
    fname  = f"campp_pred-{class_names[pred_c]}_true-{class_names[true_c]}_{os.path.basename(p)}.png"
    out_p  = os.path.join(cam_dir, fname)
    cv2.imwrite(out_p, cv2.cvtColor(overlay_u8, cv2.COLOR_RGB2BGR))
    print("[SAVE]", out_p)

#clean the hook
_fh.remove()
print(f"[DONE] Grad-CAM++ overlays saved to: {cam_dir}")

#10. Tiny machine-readable summary

summary = {
    "macro_f1": macro_f1,
    "num_classes": int(num_classes),
    "classes": class_names,
    "ap_per_class": {cls: float(ap) for cls, ap in zip(class_names, ap_scores)}
}
with open(f"{OUT_DIR}/summary.json", "w") as f:
    json.dump(summary, f, indent=2)

print(json.dumps(summary, indent=2))
print(f"\n[ALL DONE] Outputs saved in: {OUT_DIR}")